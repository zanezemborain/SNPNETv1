{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09b3f15e-813e-4b76-9b67-f57436fc80c0",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20af707-9ddf-4bff-8e5b-f96379aefb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Python Packages\n",
    "import copy\n",
    "from functools import reduce\n",
    "from glob import glob\n",
    "from glob import iglob\n",
    "import logging\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from operator import __add__\n",
    "import os\n",
    "from os.path import splitext\n",
    "from os import listdir\n",
    "import pandas as pd;\n",
    "import PIL\n",
    "from PIL import Image, ImageEnhance\n",
    "from PIL import Image, ImageOps\n",
    "from random import sample\n",
    "from random import randint\n",
    "import random;\n",
    "from scipy import stats\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from scipy.ndimage.measurements import label\n",
    "from scipy.special import softmax\n",
    "from skimage import exposure\n",
    "from skimage import feature\n",
    "from skimage import transform as tf\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "from torch.nn.modules import Conv2d, Module\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from typing import Any\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210adbd5-5bd4-4f11-9f37-a74cc936a4a0",
   "metadata": {},
   "source": [
    "Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75a79d1-4aba-4f3a-8b80-976399494b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class GaborConv2d(Module):\n",
    "#    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1,groups=1,bias=False, padding_mode=\"zeros\"):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=48, dilation=1,groups=1,bias=False, padding_mode=\"reflect\"): \n",
    "        super().__init__()\n",
    "        self.is_calculated = False\n",
    "\n",
    "        self.conv_layer = Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode)\n",
    "        self.kernel_size = self.conv_layer.kernel_size\n",
    "\n",
    "        # small addition to avoid division by zero\n",
    "        self.delta = 1e-3\n",
    "\n",
    "        #Frequency\n",
    "        self.freq = Parameter(\n",
    "            (math.pi / 2)\n",
    "            * math.sqrt(2)\n",
    "            ** (-torch.randint(0, 5, (out_channels, in_channels))).type(torch.Tensor),\n",
    "            requires_grad=True,\n",
    "        )\n",
    "        #Theta\n",
    "        self.theta = Parameter(\n",
    "            (math.pi / 8)\n",
    "            * torch.randint(0, 8, (out_channels, in_channels)).type(torch.Tensor),\n",
    "            requires_grad=True,\n",
    "        )\n",
    "        #Sigma\n",
    "        self.sigma = Parameter(math.pi / self.freq, requires_grad=True)\n",
    "\n",
    "        #Psi\n",
    "        self.psi = Parameter(\n",
    "            math.pi * torch.rand(out_channels, in_channels), requires_grad=True\n",
    "        )\n",
    "\n",
    "        self.x0 = Parameter(\n",
    "            torch.ceil(torch.Tensor([self.kernel_size[0] / 2]))[0], requires_grad=False\n",
    "        )\n",
    "        self.y0 = Parameter(\n",
    "            torch.ceil(torch.Tensor([self.kernel_size[1] / 2]))[0], requires_grad=False\n",
    "        )\n",
    "\n",
    "        self.y, self.x = torch.meshgrid(\n",
    "            [\n",
    "                torch.linspace(-self.x0 + 1, self.x0 + 0, self.kernel_size[0]),\n",
    "                torch.linspace(-self.y0 + 1, self.y0 + 0, self.kernel_size[1]),\n",
    "            ]\n",
    "        )\n",
    "        self.y = Parameter(self.y.clone());\n",
    "        self.x = Parameter(self.x.clone());\n",
    "\n",
    "        self.weight = Parameter(\n",
    "            torch.empty(self.conv_layer.weight.shape, requires_grad=True),\n",
    "            requires_grad=True,\n",
    "        )\n",
    "\n",
    "        self.register_parameter(\"freq\", self.freq)\n",
    "        self.register_parameter(\"theta\", self.theta)\n",
    "        self.register_parameter(\"sigma\", self.sigma)\n",
    "        self.register_parameter(\"psi\", self.psi)\n",
    "        self.register_parameter(\"x_shape\", self.x0)\n",
    "        self.register_parameter(\"y_shape\", self.y0)\n",
    "        self.register_parameter(\"y_grid\", self.y)\n",
    "        self.register_parameter(\"x_grid\", self.x)\n",
    "        self.register_parameter(\"weight\", self.weight)\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        if self.training:\n",
    "            self.calculate_weights()\n",
    "            self.is_calculated = False\n",
    "        if not self.training:\n",
    "            if not self.is_calculated:\n",
    "                self.calculate_weights()\n",
    "                self.is_calculated = True\n",
    "        return self.conv_layer(input_tensor)\n",
    "\n",
    "    def calculate_weights(self):\n",
    "        for i in range(self.conv_layer.out_channels):\n",
    "            for j in range(self.conv_layer.in_channels):\n",
    "                sigma = self.sigma[i, j].expand_as(self.y) \n",
    "                freq = self.freq[i, j].expand_as(self.y) \n",
    "                theta = self.theta[i, j].expand_as(self.y) \n",
    "                psi = self.psi[i, j].expand_as(self.y) \n",
    "\n",
    "                rotx = self.x * torch.cos(theta) + self.y * torch.sin(theta)\n",
    "                roty = -self.x * torch.sin(theta) + self.y * torch.cos(theta)\n",
    "\n",
    "                g = torch.exp(\n",
    "                    -0.5 * ((rotx ** 2 + roty ** 2) / (sigma + self.delta) ** 2)\n",
    "                )\n",
    "                g = g * torch.cos(freq * rotx + psi)\n",
    "                g = g / (2 * math.pi * sigma ** 2)\n",
    "                self.conv_layer.weight.data[i, j] = g\n",
    "\n",
    "    def _forward_unimplemented(self, *inputs: Any):\n",
    "        \"\"\"\n",
    "        code checkers makes implement this method,\n",
    "        looks like error in PyTorch\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = torch.tensor([x2.size()[2] - x1.size()[2]])\n",
    "        diffX = torch.tensor([x2.size()[3] - x1.size()[3]])\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class filt_cat(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x1, x2):     \n",
    "\n",
    "        # input is CHW\n",
    "        diffY = torch.tensor([x2.size()[2] - x1.size()[2]])\n",
    "        diffX = torch.tensor([x2.size()[3] - x1.size()[3]])\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return x;\n",
    "\n",
    "\n",
    "\n",
    "class AAR_Net(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(AAR_Net, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "\n",
    "        self.g0 = GaborConv2d(n_channels, n_channels, kernel_size=(144, 144))\n",
    "\n",
    "        \n",
    "        self.fc = filt_cat(n_channels, 2*n_channels)\n",
    "        self.inc = DoubleConv(2*n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 512)\n",
    "        self.up1 = Up(1024, 256, bilinear)\n",
    "        self.up2 = Up(512, 128, bilinear)\n",
    "        self.up3 = Up(256, 64, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        f = self.g0(x)\n",
    "        x0 = self.fc(f,x);\n",
    "        x1 = self.inc(x0)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        x = self.outc(x)\n",
    "        m = nn.Softmax(dim=1)\n",
    "        logits = m(x)\n",
    "        \n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f01bed-27d3-4491-80b3-2a7f1d8a1838",
   "metadata": {},
   "source": [
    "GAN Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69de6bff-96fb-4687-8537-d7555032f4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        #Embeddings Layers\n",
    "        self.label_emb = nn.Embedding(n_classes, latent_dim)\n",
    "\n",
    "        # Initial size before upsampling\n",
    "        self.init_size = img_size // 4  \n",
    "\n",
    "        #Resize\n",
    "        self.l1 = nn.Sequential(nn.Linear(latent_dim, 128 * self.init_size ** 2))\n",
    "\n",
    "        #Convolution Blocks\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, channels, 3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "\n",
    "        #Multiply Noise by Labels\n",
    "        gen_input = torch.mul(self.label_emb(labels), noise)\n",
    "\n",
    "        #Resize\n",
    "        out = self.l1(gen_input)\n",
    "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
    "\n",
    "        #Convolution Blocks\n",
    "        img = self.conv_blocks(out)\n",
    "\n",
    "        #Output\n",
    "        return img;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddef17e8-2133-4474-a240-a8789979eee1",
   "metadata": {},
   "source": [
    "Segmentation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e2cd4d-7089-4ee0-a013-01c95946b607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation_metrics(confusion_matrix, per_class=False):\n",
    "    ret = {\n",
    "        'mIoU': confusion_matrix.get_mean_class_iou(),\n",
    "        'mDice': confusion_matrix.get_mean_class_dice(),\n",
    "        'oAcc': confusion_matrix.get_overall_accuracy(),\n",
    "        'mSens': confusion_matrix.get_mean_class_sensitivity(),\n",
    "        'mSpec': confusion_matrix.get_mean_class_specificity(),\n",
    "        'mF1': confusion_matrix.get_mean_class_f1(),\n",
    "    }\n",
    "    if per_class:\n",
    "        for c,v in enumerate(confusion_matrix.get_dice_per_class()):\n",
    "            ret['Dice{}'.format(c)] = v\n",
    "        for c,v in enumerate(confusion_matrix.get_sensitivity_per_class()):\n",
    "            ret['Sens{}'.format(c)] = v\n",
    "        for c,v in enumerate(confusion_matrix.get_specificity_per_class()):\n",
    "            ret['Spec{}'.format(c)] = v\n",
    "        for c,v in enumerate(confusion_matrix.get_f1_per_class()):\n",
    "            ret['F1{}'.format(c)] = v\n",
    "        for c,v in enumerate(confusion_matrix.get_ground_truth_ratios()):\n",
    "            ret['RGt{}'.format(c)] = v\n",
    "        for c,v in enumerate(confusion_matrix.get_prediction_ratios()):\n",
    "            ret['RPr{}'.format(c)] = v\n",
    "    return ret\n",
    "\n",
    "\n",
    "class ConfusionMatrix():\n",
    "    \"\"\"Maintains a running confusion matrix for a K-class classification problem.\n",
    "    Rows corresponds to ground-truth targets and columns corresponds to predicted targets.\"\"\"\n",
    "\n",
    "    def __init__(self, k):\n",
    "        self.cm = np.zeros(shape=(k, k), dtype=object)  # array of python ints for unlimited precision\n",
    "        self.k = k\n",
    "\n",
    "    def reset(self):\n",
    "        self.cm.fill(0)\n",
    "\n",
    "    def add(self, predicted, target):\n",
    "        \"\"\"\n",
    "        Adds new results to the confusion matrix. Filters elements without ground truth (class = -100).\n",
    "\n",
    "        :param predicted: N, BHW or BDHW-sized tensor of class integers or NK, BKHW or BKDHW-sized tensor\n",
    "                          of predicted probabilities\n",
    "        :param target: N, BHW or BDHW-sized tensor of class integers or NK, BKHW or BKDHW-sized tensor\n",
    "                          of one-hot encoded classes\n",
    "        \"\"\"\n",
    "        # TODO: rewrite into pytorch for speed (no need to copy back to device)\n",
    "\n",
    "        if isinstance(predicted, torch.Tensor):\n",
    "            predicted = predicted.detach().cpu().numpy()\n",
    "        if isinstance(target, torch.Tensor):\n",
    "            target = target.detach().cpu().numpy()\n",
    "\n",
    "        if np.ndim(predicted) > 1 and predicted.shape[1] == self.k:\n",
    "            predicted = np.argmax(predicted, 1)\n",
    "        else:\n",
    "            assert (predicted.max() < self.k) and (predicted.min() >= 0), \\\n",
    "                'predicted values are not between 0 and k-1'\n",
    "\n",
    "        if np.ndim(target) > 1 and target.shape[1] == self.k:\n",
    "            assert (target >= 0).all() and (target <= 1).all(), \\\n",
    "                'in one-hot encoding, target values should be 0 or 1'\n",
    "            invalid_idx = target.sum(1) < 0.5\n",
    "            target = np.argmax(target, 1)\n",
    "            target[invalid_idx] = -100\n",
    "\n",
    "        predicted = np.ravel(predicted)\n",
    "        target = np.ravel(target)\n",
    "        assert predicted.shape[0] == target.shape[0], \\\n",
    "            'number of targets and predicted outputs do not match'\n",
    "\n",
    "        # Remove predictions for elements without ground truth\n",
    "        valid_idx = target != -100\n",
    "        target = target[valid_idx]\n",
    "        predicted = predicted[valid_idx]\n",
    "\n",
    "        # from https://github.com/pytorch/tnt/blob/master/torchnet/meter/confusionmeter.py\n",
    "        # (sklearn.metrics.confusion_matrix is 100x slower)\n",
    "\n",
    "        \n",
    "        x = predicted + self.k * target\n",
    " \n",
    "        \n",
    "        bincount_2d = np.bincount(x.astype(np.int64),\n",
    "                                  minlength=self.k ** 2)\n",
    "        \n",
    "        #print(bincount_2d.size)\n",
    "        #print(self.k ** 2)\n",
    "        \n",
    "        assert bincount_2d.size == self.k ** 2\n",
    "        cm = bincount_2d.reshape((self.k, self.k))\n",
    "\n",
    "        self.cm += cm\n",
    "\n",
    "    def value(self, normalized=False):\n",
    "        \"\"\"\n",
    "        :return confusion matrix of K rows and K columns\n",
    "        \"\"\"\n",
    "        conf = self.cm.astype(np.float64)\n",
    "        if normalized:\n",
    "            return conf / conf.sum(1).clip(min=1e-12)[:, None]\n",
    "        else:\n",
    "            return conf\n",
    "\n",
    "    def get_iou_per_class(self):\n",
    "        \"\"\"\n",
    "        :return per-class intersection-over-union / Jaccard coefficient (NaN if class not present nor predicted)\n",
    "        \"\"\"\n",
    "        cm = self.value()\n",
    "        tp = np.diag(cm)\n",
    "        rowsum = cm.sum(axis=0)\n",
    "        colsum = cm.sum(axis=1)\n",
    "        with np.errstate(invalid='ignore'):\n",
    "            return tp / (rowsum + colsum - tp)\n",
    "\n",
    "    def get_mean_class_iou(self):\n",
    "        \"\"\"\n",
    "        :return mean per-class intersection-over-union / Jaccard coefficient (over classes present)\n",
    "        \"\"\"\n",
    "        iou = self.get_iou_per_class()\n",
    "        iou = iou[~np.isnan(iou)]\n",
    "        return np.mean(iou)\n",
    "\n",
    "    def get_overall_accuracy(self):\n",
    "        \"\"\"\n",
    "        :return overall sensitivity (class-unspecific)\n",
    "        \"\"\"\n",
    "        cm = self.value()\n",
    "        tp = np.diag(cm).sum()\n",
    "        oa = tp / max(1, np.sum(cm))\n",
    "        return oa\n",
    "\n",
    "    def get_sensitivity_per_class(self):\n",
    "        \"\"\"\n",
    "        :return per-class sensitivity (NaN if class not present)\n",
    "        \"\"\"\n",
    "        cm = self.value()\n",
    "        tp = np.diag(cm)\n",
    "        with np.errstate(invalid='ignore'):\n",
    "            return tp / np.sum(cm, axis=1)\n",
    "\n",
    "    def get_mean_class_sensitivity(self):\n",
    "        \"\"\"\n",
    "        :return mean per-class sensitivity (over classes present)\n",
    "        \"\"\"\n",
    "        sens = self.get_sensitivity_per_class()\n",
    "        sens = sens[~np.isnan(sens)]\n",
    "        return np.mean(sens)\n",
    "\n",
    "\n",
    "    def get_specificity_per_class(self):\n",
    "        \"\"\"\n",
    "        :return per-class specificity (NaN if class not present)\n",
    "        \"\"\"\n",
    "        cm = copy.deepcopy(self.value())\n",
    "        tp = np.diag(copy.deepcopy(cm))\n",
    "        tn = copy.deepcopy(tp);\n",
    "        for i in range(0,len(tn)):\n",
    "          tn[i] = tp.sum() - tp[i];\n",
    "          cm[i,i] = 0;\n",
    "\n",
    "        with np.errstate(invalid='ignore'):\n",
    "            return tn /(tn +  np.sum(cm, axis=0))\n",
    "\n",
    "    def get_mean_class_specificity(self):\n",
    "        \"\"\"\n",
    "        :return mean per-class specificity (over classes present)\n",
    "        \"\"\"\n",
    "        spec = self.get_specificity_per_class()\n",
    "        spec = spec[~np.isnan(spec)]\n",
    "        return np.mean(spec)\n",
    "\n",
    "    def get_f1_per_class(self):\n",
    "        \"\"\"\n",
    "        :return per-class f1 (NaN if class not present)\n",
    "        \"\"\"\n",
    "        cm = self.value()\n",
    "        tp = np.diag(cm)\n",
    "        with np.errstate(invalid='ignore'):\n",
    "            return tp / (0.5*(np.sum(cm, axis=1) + np.sum(cm, axis=0)))\n",
    "\n",
    "\n",
    "    def get_mean_class_f1(self):\n",
    "        \"\"\"\n",
    "        :return mean per-class f1 (over classes present)\n",
    "        \"\"\"\n",
    "        f1 = self.get_f1_per_class()\n",
    "        f1 = f1[~np.isnan(f1)]\n",
    "        return np.mean(f1)\n",
    "\n",
    "\n",
    "\n",
    "    def get_dice_per_class(self):\n",
    "        \"\"\"\n",
    "        :return per-class Dice coefficient (NaN if class not present nor predicted)\n",
    "        \"\"\"\n",
    "        with np.errstate(invalid='ignore'):\n",
    "            jacc = self.get_iou_per_class()\n",
    "            return 2 * jacc / (jacc + 1)\n",
    "\n",
    "    def get_mean_class_dice(self):\n",
    "        \"\"\"\n",
    "        :return mean per-class Dice coefficient (over classes present)\n",
    "        \"\"\"\n",
    "        dice = self.get_dice_per_class()\n",
    "        dice = dice[~np.isnan(dice)]\n",
    "        return np.mean(dice)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee84aa5-db91-47ce-b6cf-e5b9865d21fc",
   "metadata": {},
   "source": [
    "Find Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e51dee3-6570-43af-a2bb-ce484b288858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_edges(color_mask):\n",
    "    \n",
    "\n",
    "    #Dimensions\n",
    "    [rows, cols] = color_mask.shape\n",
    "\n",
    "    struct1 = ndimage.generate_binary_structure(2, 2)\n",
    "\n",
    "    all_edges = np.zeros([rows, cols]);\n",
    "    for color_idx in range(0,3):\n",
    "\n",
    "        #Binary Mask\n",
    "        mask = copy.deepcopy(color_mask);\n",
    "        mask[np.where(color_mask==color_idx)] = 1;\n",
    "        mask[np.where(color_mask!=color_idx)] = 0;\n",
    "\n",
    "        #Empty Positions\n",
    "        up = np.zeros([rows, cols])\n",
    "        down = np.zeros([rows, cols])\n",
    "        left = np.zeros([rows, cols])\n",
    "        right = np.zeros([rows, cols])\n",
    "        up_left = np.zeros([rows, cols])\n",
    "        up_right = np.zeros([rows, cols])\n",
    "        down_left = np.zeros([rows, cols])\n",
    "        down_right = np.zeros([rows, cols])\n",
    "\n",
    "        #Shift Positions\n",
    "        up[:rows-1, :] = mask[1:rows,:]\n",
    "        down[1:rows,:] = mask[0:rows-1,:]\n",
    "        left[:,:cols-1] = mask[:,1:cols]\n",
    "        right[:,1:cols] = mask[:,:cols-1]\n",
    "        up_left[0:rows-1,0:cols-1] = mask[1:rows,1:cols]\n",
    "        up_right[0:rows-1,1:cols] = mask[1:rows,0:cols-1]\n",
    "        down_left[1:rows,0:cols-1] = mask[0:rows-1,1:cols]\n",
    "        down_right[1:rows,1:cols] = mask[0:rows-1,0:cols-1]\n",
    "\n",
    "        #Fill if Coincides with the Center\n",
    "        conn = np.zeros([8,rows, cols])\n",
    "        conn[0] = mask*down_right\n",
    "        conn[1] = mask*down\n",
    "        conn[2] = mask*down_left\n",
    "        conn[3] = mask*right\n",
    "        conn[4] = mask*left\n",
    "        conn[5] = mask*up_right\n",
    "        conn[6] = mask*up\n",
    "        conn[7] = mask*up_left\n",
    "        \n",
    "\n",
    "        #Find Edges & Non-Edges\n",
    "        sum_conn = np.sum(conn,axis=0)\n",
    "        not_full = np.where(sum_conn<8,np.full_like(sum_conn, 1),np.full_like(sum_conn, 0))\n",
    "        salient = np.where(sum_conn>0,np.full_like(sum_conn, 1),np.full_like(sum_conn, 0))\n",
    "        edge = not_full*salient;\n",
    "   \n",
    "        if(color_idx==1):\n",
    "            all_edges = edge;\n",
    "\n",
    "        else:\n",
    "            all_edges +=edge;\n",
    "\n",
    "\n",
    "    #Remove Overlap\n",
    "    all_edges[np.where(all_edges>1)] = 1;\n",
    "    all_edges = ndimage.binary_dilation(all_edges, structure=struct1).astype(all_edges.dtype)\n",
    "\n",
    "\n",
    "\n",
    "    return all_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec417be9-2b73-4fc3-82e2-27a5454e95a3",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2995bc82-15b4-4782-b000-2896c9bb0ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicDataset(Dataset):\n",
    "    \n",
    "    \n",
    "    def __init__(self, Real_CCM, Fake_CCM, Train):\n",
    "        \n",
    "\n",
    "\n",
    "        #Attributes\n",
    "        self.Real_CCM = Real_CCM;\n",
    "        self.Fake_CCM = Fake_CCM;\n",
    "        self.Train = Train;        \n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        #Length\n",
    "        if(self.Train==1):\n",
    "          return int(6*np.shape(self.Real_CCM)[1])\n",
    "        else:\n",
    "          return int(3*np.shape(self.Real_CCM)[1])\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "\n",
    "                \n",
    "        #First Layer Parameters\n",
    "        layer_1 = i%3;\n",
    "        generated_1 = i%2;\n",
    "        if(self.Train==1):\n",
    "            idx_1 = math.floor(i/6);         \n",
    "        else:\n",
    "            idx_1 = math.floor(i/3);\n",
    "            generated_1 = 0;\n",
    "        \n",
    "\n",
    "        #First Image\n",
    "        img_1 = self.Real_CCM[layer_1,idx_1,:,:].squeeze().copy();\n",
    "        \n",
    "        #Second Layer Parameters\n",
    "        layer_2 = randint(0,2);\n",
    "        generated_2 = randint(0,1);\n",
    "        if(self.Train==1):\n",
    "            idx_2 = randint(0, np.shape(self.Real_CCM)[1]-1)       \n",
    "        else:\n",
    "            idx_2 = randint(0, np.shape(self.Real_CCM)[1]-1) \n",
    "            generated_2 = 0;\n",
    "\n",
    "  \n",
    "        #Second Image\n",
    "        img_2 = self.Real_CCM[layer_2,idx_2,:,:].squeeze().copy();\n",
    "        \n",
    "        \n",
    "                \n",
    "        #Iterate         \n",
    "        for g_index in range(0,4):\n",
    "\n",
    "           \n",
    "        \n",
    "            #Crop Image 1\n",
    "            if(generated_1==0):\n",
    "\n",
    "\n",
    "                #Row and Column\n",
    "                row = randint(0,191);\n",
    "                col = randint(0,191);\n",
    "                \n",
    "                #Crop Image\n",
    "                cropped_img_1 = img_1[row:row + 192,col:col +  192].copy();\n",
    "                cropped_img_1 = (cropped_img_1 - np.min(cropped_img_1))/(np.max(cropped_img_1) - np.min(cropped_img_1))\n",
    "         \n",
    "            else:\n",
    "                idx_1 = randint(0, np.shape(self.Fake_CCM)[1]-1)  \n",
    "                cropped_img_1 =  self.Fake_CCM[layer_1,idx_1,:,:].squeeze().copy();    \n",
    "\n",
    "            #Crop Image 2\n",
    "            if(generated_2==0):\n",
    "\n",
    "\n",
    "                #Row and Column\n",
    "                row = randint(0,191);\n",
    "                col = randint(0,191);\n",
    "                \n",
    "                #Crop Image\n",
    "                cropped_img_2 = img_2[row:row + 192,col:col +  192].copy();                \n",
    "                cropped_img_2 = (cropped_img_2 - np.min(cropped_img_2))/(np.max(cropped_img_2) - np.min(cropped_img_2))\n",
    "         \n",
    "            else:\n",
    "                idx_2 = randint(0, np.shape(self.Fake_CCM)[1]-1)  \n",
    "                cropped_img_2 =  self.Fake_CCM[layer_2,idx_2,:,:].squeeze().copy();  \n",
    "              \n",
    "                     \n",
    "            #Flip Image 1\n",
    "            if(randint(0,1)==1):\n",
    "                cropped_img_1 = np.fliplr(cropped_img_1).copy();\n",
    "            if(randint(0,1)==1):\n",
    "                cropped_img_1 = np.flipud(cropped_img_1).copy();\n",
    "        \n",
    "            #Flip Image 2\n",
    "            if(randint(0,1)==1):\n",
    "                cropped_img_2 = np.fliplr(cropped_img_2).copy();\n",
    "            if(randint(0,1)==1):\n",
    "                cropped_img_2 = np.flipud(cropped_img_2).copy();    \n",
    "\n",
    "\n",
    "            #Normalize Images\n",
    "            if(np.mean(cropped_img_1) < np.mean(cropped_img_2)):\n",
    "                cropped_img_2 = cropped_img_2 * np.mean(cropped_img_1)/np.mean(cropped_img_2);\n",
    "            else:\n",
    "                cropped_img_1 = cropped_img_1 * np.mean(cropped_img_2)/np.mean(cropped_img_1);\n",
    "                \n",
    "            cropped_img_1 = cropped_img_1 - 0.5;\n",
    "            cropped_img_2 = cropped_img_2 - 0.5;\n",
    "\n",
    "\n",
    "            #Create Masks\n",
    "            mask_1 = layer_1*np.ones(np.shape(cropped_img_1))\n",
    "            mask_2 = layer_2*np.ones(np.shape(cropped_img_2))\n",
    "            \n",
    "            \n",
    "            #Produce Filter\n",
    "            width = 192;\n",
    "            height = 192;\n",
    "            original_filter =  np.zeros((height,width))\n",
    "            x = randint(80,112);\n",
    "            angle = 0;\n",
    "            for y in range(0,height):\n",
    "\n",
    "                #Update\n",
    "                angle = angle + 0.5 - random.random();\n",
    "                x = int(x + 0.1 * np.cos(angle));\n",
    "\n",
    "                #Fill Filter\n",
    "                if (x > 0 and x< width):\n",
    "                    original_filter[y,0:x] = 1;\n",
    "\n",
    "                #Boundary Conditions\n",
    "                if (x < 0):\n",
    "                  x = width;\n",
    "                if (x > width):\n",
    "                  x = -1;\n",
    "\n",
    "\n",
    "            #Flip Filter\n",
    "            if(randint(0,1)==1):\n",
    "              original_filter = np.fliplr(original_filter).copy();\n",
    "            if(randint(0,1)==1):\n",
    "              original_filter = np.flipud(original_filter).copy();\n",
    "\n",
    "            #Invert Filter\n",
    "            if(randint(0,1)==1):\n",
    "              original_filter = 1 - original_filter;\n",
    "\n",
    "\n",
    " \n",
    "            #Smooth Filter\n",
    "            sigma_var = randint(1,21);\n",
    "            filter_smooth = ndimage.gaussian_filter(original_filter, sigma=(sigma_var, sigma_var), order=0)\n",
    "            filter_smooth_opp = 1 - filter_smooth;\n",
    "            filter_binary = np.round(filter_smooth);\n",
    "            filter_binary_opp = 1 - filter_binary;\n",
    "\n",
    "\n",
    "\n",
    "            #Apply Filters\n",
    "            if(randint(0,1)==1):\n",
    "                img = (cropped_img_1 * filter_smooth_opp) + (cropped_img_2 * filter_smooth);\n",
    "                mask = (mask_1 * filter_binary_opp) + (mask_2 * filter_binary);\n",
    "            else:\n",
    "                img = cropped_img_1.copy();\n",
    "                mask = mask_1.copy();\n",
    "\n",
    "\n",
    "            #Find Edges\n",
    "            edge = find_edges(mask);\n",
    "\n",
    "            #Expand Dim\n",
    "            img = np.expand_dims(img,axis = 0);\n",
    "            mask = np.expand_dims(mask,axis = 0);\n",
    "            edge = np.expand_dims(edge,axis = 0);\n",
    "\n",
    "            #Add to Group\n",
    "            if(g_index ==0):\n",
    "                images = img;\n",
    "                masks = mask; \n",
    "                edges = edge;   \n",
    "            else:\n",
    "                images = np.concatenate((images, img), 0);\n",
    "                masks = np.concatenate((masks, mask), 0);\n",
    "                edges = np.concatenate((edges, edge), 0);\n",
    "\n",
    "            \n",
    "      \n",
    "        \n",
    "        return {'images': images, 'masks': masks, 'edges': edges}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fc348b-65f1-4d8b-bebf-bfdc0323dbdb",
   "metadata": {},
   "source": [
    "Evaluate Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c4f837-a3da-4088-86e5-1ecf7ae321f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_net(net, loader, tissues, device, n_val):\n",
    "    \n",
    "    #Evaluation Mode\n",
    "    net.eval();\n",
    "    \n",
    "\n",
    "    #Initialize\n",
    "    val_dice = [];\n",
    "    val_dice_0 = [];\n",
    "    val_dice_1 = [];\n",
    "    val_dice_2 = [];\n",
    "    val = np.zeros((tissues+1));\n",
    "    \n",
    "    #Display Progress Bar\n",
    "    with tqdm(total=n_val, desc='Validation round', unit='img', leave=False) as pbar:\n",
    "        \n",
    "        #Iterate \n",
    "        for batch in loader:\n",
    "          \n",
    "            #Load \n",
    "            imgs = torch.from_numpy(np.reshape(np.array(batch['images']), (-1,1,192,192))).to(device=device, dtype=torch.float32);\n",
    "            targets = torch.from_numpy(np.reshape(np.array(batch['masks']), (-1,1,192,192))).to(device=device, dtype=torch.long);\n",
    "\n",
    "            #Predict\n",
    "            predictions = net(imgs);\n",
    "            \n",
    "                \n",
    "            #DSC Calculation\n",
    "            cm = ConfusionMatrix(tissues)\n",
    "            cm.add(predictions, targets.squeeze(1))\n",
    "            acc_out = segmentation_metrics(cm);\n",
    "            f1_per_class = cm.get_f1_per_class();                \n",
    "            val_dice.append(acc_out['mF1']);\n",
    "            val_dice_0.append(f1_per_class[0]);\n",
    "            val_dice_1.append(f1_per_class[1]);\n",
    "            val_dice_2.append(f1_per_class[2]);  \n",
    "            \n",
    "            \n",
    "            #Update Progress Bar\n",
    "            pbar.update(imgs.shape[0]);\n",
    "\n",
    "           \n",
    "    #Average Dice\n",
    "    val[0] =  np.nanmean(np.array(val_dice))\n",
    "    val[1] =  np.nanmean(np.array(val_dice_0))\n",
    "    val[2] =  np.nanmean(np.array(val_dice_1))\n",
    "    val[3] =  np.nanmean(np.array(val_dice_2))\n",
    "    \n",
    "    \n",
    "    return val;\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7757d47-791c-45aa-8cc5-277f04db5c87",
   "metadata": {},
   "source": [
    "Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a18411c-f717-4c94-a455-0fe20b4ad666",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_net(net, epochs, tissues, lr, batch_size, g , python_path, torch_path, Experiment_Name, Model_Name):\n",
    "\n",
    "\n",
    "\n",
    "    #Load Numpy Files\n",
    "    SNP_Train = np.load(python_path + 'AAR_Net_Images_Training_SNP.npy');\n",
    "    Epithelium_Train = np.load(python_path + 'AAR_Net_Images_Training_Epithelium.npy');\n",
    "    Stroma_Train = np.load(python_path + 'AAR_Net_Images_Training_Stroma.npy');\n",
    "    SNP_Val = np.load(python_path + 'AAR_Net_Images_Validation_SNP.npy');\n",
    "    Epithelium_Val = np.load(python_path + 'AAR_Net_Images_Validation_Epithelium.npy');\n",
    "    Stroma_Val = np.load(python_path + 'AAR_Net_Images_Validation_Stroma.npy');  \n",
    "    \n",
    "    \n",
    "    #Shuffle Data\n",
    "    indices = np.arange(0,np.shape(SNP_Train)[0]);\n",
    "    np.random.shuffle(indices);\n",
    "    SNP_Train = np.expand_dims(SNP_Train[indices],axis = 0)    \n",
    "    indices = np.arange(0,np.shape(SNP_Val)[0]);\n",
    "    np.random.shuffle(indices);\n",
    "    SNP_Val = np.expand_dims(SNP_Val[indices],axis = 0)   \n",
    "    indices = np.arange(0,np.shape(Epithelium_Train)[0]);\n",
    "    np.random.shuffle(indices);\n",
    "    Epithelium_Train = np.expand_dims(Epithelium_Train[indices],axis = 0)      \n",
    "    indices = np.arange(0,np.shape(Epithelium_Val)[0]);\n",
    "    np.random.shuffle(indices);\n",
    "    Epithelium_Val = np.expand_dims(Epithelium_Val[indices],axis = 0)   \n",
    "    indices = np.arange(0,np.shape(Stroma_Train)[0]);\n",
    "    np.random.shuffle(indices);\n",
    "    Stroma_Train = np.expand_dims(Stroma_Train[indices],axis = 0)     \n",
    "    indices = np.arange(0,np.shape(Stroma_Val)[0]);\n",
    "    np.random.shuffle(indices);\n",
    "    Stroma_Val = np.expand_dims(Stroma_Val[indices],axis = 0)  \n",
    "    \n",
    "        \n",
    "    \n",
    "    #Concatenate\n",
    "    Real_CCM_Train = np.concatenate((SNP_Train, Epithelium_Train, Stroma_Train), 0);\n",
    "    Real_CCM_Val = np.concatenate((SNP_Val, Epithelium_Val, Stroma_Val), 0);       \n",
    "\n",
    "\n",
    "    #Generate Fake Images\n",
    "    Fake_CCM_Train = np.zeros((3,32800,192,192))\n",
    "    for layer in range(0,3):\n",
    "        for idx in range(0,32800):\n",
    "            latent_dim = 400;\n",
    "            z = Variable(FloatTensor(np.random.normal(0, 1, (1, latent_dim))))\n",
    "            labels_fake = np.array(layer* np.ones((1,1)).squeeze());\n",
    "            labels_fake = Variable(LongTensor(labels_fake))\n",
    "            fake_img = generator(z, labels_fake)\n",
    "            Fake_CCM_Train[layer,idx,:,:] = fake_img.cpu().detach().numpy().squeeze();\n",
    "    Fake_CCM_Val = [];\n",
    "\n",
    "      \n",
    "    #Construct Datasets\n",
    "    train_dataset = BasicDataset(Real_CCM_Train, Fake_CCM_Train, 1);\n",
    "    val_dataset = BasicDataset(Real_CCM_Val, Fake_CCM_Val, 0);\n",
    "\n",
    "    #Construct Loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True);\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=16, pin_memory=True);\n",
    "\n",
    "\n",
    "    #Write the Training Parameters to the Log File\n",
    "    logging.info(f'''Started training:\n",
    "        Epochs:          {epochs}\n",
    "        Batch size:      {batch_size}\n",
    "        Learning rate:   {lr}\n",
    "        Training size:   {len(train_dataset)}\n",
    "        Validation size: {len(val_dataset)}\n",
    "        Device:          {device.type}\n",
    "    ''');\n",
    "\n",
    "\n",
    "    #Optimizer and Scheduler\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=1e-8);\n",
    "    scheduler = StepLR(optimizer, step_size = 20, gamma = 0.5)\n",
    "  \n",
    "    \n",
    "    #Results\n",
    "    training = np.zeros((tissues+1,epochs));\n",
    "    validation = np.zeros((tissues+1,epochs));\n",
    "\n",
    "\n",
    "    #Iterate through Epochs\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        #Begin Training\n",
    "        net.train();\n",
    "\n",
    "\n",
    "        #Initialize Epoch Loss\n",
    "        epoch_loss = 0;\n",
    "        loss_count = 0;\n",
    "    \n",
    "        #Initialize Training Sensitivity & Specificity\n",
    "        train_dice = [];\n",
    "        train_dice_0 = [];\n",
    "        train_dice_1 = [];\n",
    "        train_dice_2 = [];\n",
    "\n",
    "\n",
    "        #Display Progress Bar\n",
    "        with tqdm(total=4*len(train_dataset), desc=f'Epoch {epoch + 1}/{epochs}', unit='img') as pbar:\n",
    "            \n",
    "            \n",
    "            #Iterate through the Batches in the Training Set\n",
    "            for batch in train_loader:\n",
    "                \n",
    "                imgs = torch.from_numpy(np.reshape(np.array(batch['images']), (-1,1,192,192))).to(device=device, dtype=torch.float32);\n",
    "                targets = torch.from_numpy(np.reshape(np.array(batch['masks']), (-1,1,192,192))).to(device=device, dtype=torch.long);\n",
    "                edges = torch.from_numpy(np.reshape(np.array(batch['edges']), (-1,1,192,192))).to(device=device, dtype=torch.float32);\n",
    "\n",
    "                \n",
    "\n",
    "                #Predict the Class\n",
    "                predictions = net(imgs);\n",
    "          \n",
    "\n",
    "                #Ratio\n",
    "                total_size = np.size(targets.cpu().numpy());\n",
    "                class_0 = np.where(targets.cpu().numpy()==0);            \n",
    "                class_1 = np.where(targets.cpu().numpy()==1);                \n",
    "                class_2 = np.where(targets.cpu().numpy()==2); \n",
    "              \n",
    "                if(len(class_0[0]) !=0):\n",
    "                    ratio_0 = total_size/len(class_0[0]);    \n",
    "                else:\n",
    "                    ratio_0 = 0;\n",
    "                   \n",
    "                if(len(class_1[0]) !=0):\n",
    "                    ratio_1 = total_size/len(class_1[0]);    \n",
    "                else:\n",
    "                    ratio_1 = 0;               \n",
    "                \n",
    "                if(len(class_2[0]) !=0):\n",
    "                    ratio_2 = total_size/len(class_2[0]);    \n",
    "                else:\n",
    "                    ratio_2 = 0;               \n",
    "                    \n",
    "                \n",
    "                #Inverse Class Weights\n",
    "                weights = [np.power(ratio_0,1/2), np.power(ratio_1, 1/2), np.power(ratio_2,1/2)];\n",
    "                class_weights = torch.FloatTensor(weights).cuda();   \n",
    "\n",
    "\n",
    "                #Calculate Loss\n",
    "                criterion_= nn.CrossEntropyLoss(weight = class_weights, reduction = 'none');\n",
    "                loss_matrix = criterion_(predictions, targets.squeeze(1)); \n",
    "                loss_1 = torch.mean(loss_matrix);\n",
    "                loss_2 = torch.mean(loss_matrix*edges);\n",
    "\n",
    "\n",
    "                loss = loss_1 + 2*loss_2;\n",
    "                epoch_loss += loss.item()\n",
    "                loss_count += 1;\n",
    "\n",
    "  \n",
    "                #DSC Calculation\n",
    "                cm = ConfusionMatrix(tissues)\n",
    "                cm.add(predictions, targets.squeeze(1))\n",
    "                acc_out = segmentation_metrics(cm);\n",
    "                f1_per_class = cm.get_f1_per_class();   \n",
    "                train_dice.append(acc_out['mF1']);\n",
    "                train_dice_0.append(f1_per_class[0]);\n",
    "                train_dice_1.append(f1_per_class[1]);\n",
    "                train_dice_2.append(f1_per_class[2]);\n",
    "\n",
    "\n",
    "\n",
    "                #Update \n",
    "                pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
    "\n",
    "                #Backpropagation\n",
    "                optimizer.zero_grad();\n",
    "                loss.backward();\n",
    "                optimizer.step();\n",
    "\n",
    "                #Update Progress Bar\n",
    "                pbar.update(imgs.shape[0])\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "        #Average Training Dice\n",
    "        training[0,epoch] = np.nanmean(np.array(train_dice));\n",
    "        training[1,epoch] = np.nanmean(np.array(train_dice_0));\n",
    "        training[2,epoch] = np.nanmean(np.array(train_dice_1));\n",
    "        training[3,epoch] = np.nanmean(np.array(train_dice_2));\n",
    "\n",
    "\n",
    "        #Average Validation Dice\n",
    "        validation[:,epoch] = eval_net(net, val_loader, tissues, device, len(train_dataset));\n",
    "\n",
    "        \n",
    "        #Print Results\n",
    "        logging.info('Average Train Dice: ' + str(training[0,epoch]))\n",
    "        logging.info('Average Train Dice SNP: ' + str(training[1,epoch]))  \n",
    "        logging.info('Average Train Dice Epithelium: ' + str(training[2,epoch]))  \n",
    "        logging.info('Average Train Dice Stroma: ' + str(training[3,epoch]))  \n",
    "        \n",
    "        logging.info('Average Val Dice: ' + str(validation[0,epoch]))   \n",
    "        logging.info('Average Val Dice SNP: ' + str(validation[1,epoch]))  \n",
    "        logging.info('Average Val Dice Epithelium: ' + str(validation[2,epoch]))  \n",
    "        logging.info('Average Val Dice Stroma: ' + str(validation[3,epoch]))  \n",
    " \n",
    "\n",
    "        #Learning Rate Scheduler\n",
    "        scheduler.step()            \n",
    "            \n",
    "\n",
    "        #Save Model\n",
    "        torch.save(net.state_dict(), torch_path + Model_Name + '_' + Experiment_Name + '_Group_' + str(g) + '_Epoch_' +str(epoch+1) +'.pth')\n",
    "        \n",
    "        #Save Training Metrics\n",
    "        np.save(torch_path  +'Training_Dice_'+ Model_Name + '_' + Experiment_Name + '_Group_' + str(g) + '_Epoch_' +str(epoch+1) +'.npy', training);\n",
    "        np.save(torch_path  +'Validation_Dice_'+ Model_Name + '_' + Experiment_Name + '_Group_' + str(g) + '_Epoch_' +str(epoch+1) +'.npy', validation);\n",
    "\n",
    "\n",
    "\n",
    "    return training, validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e7695e-5b75-4e05-82f9-7c441eb63724",
   "metadata": {},
   "source": [
    "Load Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649522fb-4922-43b0-b2a9-aa073aca7f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path\n",
    "python_path = r'/hpc/group/viplab/zzz3/SNP_Segmentation/Files/Python/AAR-Net/';\n",
    "torch_path = r'/hpc/group/viplab/zzz3/SNP_Segmentation/Files/Torch/AAR-Net/';\n",
    "\n",
    "#Parameters\n",
    "experiment = 'Original'\n",
    "\n",
    "#Hyper Parameters\n",
    "latent_dim = 400;\n",
    "n_classes = 3;\n",
    "img_size = 192;\n",
    "channels = 1;\n",
    "\n",
    "\n",
    "#Cast to Cuda\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "if cuda:\n",
    "    FloatTensor = torch.cuda.FloatTensor\n",
    "    LongTensor = torch.cuda.LongTensor\n",
    "else:\n",
    "    FloatTensor = torch.FloatTensor\n",
    "    LongTensor = torch.LongTensor\n",
    "\n",
    "#Attempt to use GPU instead of CPU\n",
    "CUDA_VISIBLE_DEVICES=0\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu');\n",
    "\n",
    "#Load Generator\n",
    "generator = Generator();\n",
    "generator.load_state_dict(torch.load(torch_path +  'Generator_' + experiment + '.pth', map_location=device));\n",
    "generator.to(device=device)\n",
    "\n",
    "#Set the Network to Eval Mode for Prediction\n",
    "generator.eval();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be609c3-049e-4f32-8dca-9cb8ceecbeb9",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225551b4-2fa0-4d14-ad4c-3a616eaf94f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "Experiment_Name = 'Original';\n",
    "Model_Name = 'AAR_Net';\n",
    "\n",
    "\n",
    "#Hyper Parameters\n",
    "epochs = 80;\n",
    "lr = 0.005; \n",
    "batch_size = 5;\n",
    "tissues = 3; \n",
    "channels = 1;\n",
    "\n",
    "\n",
    "#Set up Basic Configuration of the Log File\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s');\n",
    "logging.info(f'Using device {device}');\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    if(cuda): \n",
    "\n",
    "        for g in range(0,5):\n",
    "\n",
    "\n",
    "            #Load Network \n",
    "            net = AAR_Net(n_channels=channels, n_classes=tissues); \n",
    "            net.to(device=device)\n",
    "\n",
    "            #Train\n",
    "            training, validation  =  train_net(net, epochs, tissues, lr, batch_size, g , python_path, torch_path, Experiment_Name, Model_Name);\n",
    "\n",
    "            \n",
    "            #Save Training Metrics\n",
    "            np.save(torch_path  +'Training_Dice_'+ Model_Name +'_' + Experiment_Name +'_Group_' + str(g) + '.npy', training);\n",
    "            np.save(torch_path  +'Validation_Dice_'+  Model_Name +'_' + Experiment_Name +'_Group_' + str(g) + '.npy', validation);\n",
    "\n",
    "            \n",
    "            epoch = np.argmax(validation[0,40:]) + 40;\n",
    "\n",
    "\n",
    "            #Delete Other Models\n",
    "            for i in range(1,epochs+1):\n",
    "                if(i !=epoch+1):\n",
    "                    if(os.path.exists(torch_path + Model_Name + '_' + Experiment_Name + '_Group_' + str(g) + '_Epoch_' +str(i) +'.pth')):\n",
    "                            os.remove(torch_path + Model_Name + '_' + Experiment_Name + '_Group_' + str(g) + '_Epoch_' +str(i) +'.pth');\n",
    "\n",
    "                if(os.path.exists(torch_path  +'Training_Dice_'+ Model_Name + '_' + Experiment_Name + '_Group_' + str(g) + '_Epoch_' +str(i) +'.npy')):\n",
    "                    os.remove(torch_path  +'Training_Dice_'+ Model_Name + '_' + Experiment_Name + '_Group_' + str(g) + '_Epoch_' +str(i) +'.npy');\n",
    "                    os.remove(torch_path  +'Validation_Dice_'+ Model_Name + '_' + Experiment_Name + '_Group_' + str(g) + '_Epoch_' +str(i) +'.npy');\n",
    "\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    \n",
    "  pass  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
