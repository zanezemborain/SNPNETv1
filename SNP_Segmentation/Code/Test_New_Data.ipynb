{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c9d6a6a-5d5e-4bb1-b6ab-fd7df61e2be8",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e31154-0f57-40c1-a717-1b036e8a2bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "!pip install pingouin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0247e85-6d1b-4ebb-93b7-171a81f65297",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Python Packages\n",
    "import copy;\n",
    "import cv2;\n",
    "import csv;\n",
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "from glob import glob\n",
    "from glob import iglob\n",
    "import logging\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from operator import __add__\n",
    "import os\n",
    "from os.path import splitext\n",
    "from os import listdir\n",
    "import pandas as pd;\n",
    "from PIL import Image, ImageOps\n",
    "import PIL\n",
    "import pingouin as pg\n",
    "from random import randint\n",
    "import random;\n",
    "import sys\n",
    "from scipy.stats import wilcoxon\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from scipy.ndimage.measurements import label\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from skimage import exposure\n",
    "from skimage import feature\n",
    "from skimage import transform as tf\n",
    "from skimage import morphology\n",
    "from skimage.morphology import skeletonize\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.nn import Parameter\n",
    "from torch.nn.modules import Conv2d, Module\n",
    "from tqdm import tqdm\n",
    "from typing import Any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import xlsxwriter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc9fb07-97c7-48aa-872d-fe387b282ca1",
   "metadata": {},
   "source": [
    "Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b11beb-c7ce-4dcf-a85b-cce3fa812e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaborConv2d(Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=48, dilation=1,groups=1,bias=False, padding_mode=\"reflect\"): \n",
    "        super().__init__()\n",
    "        self.is_calculated = False\n",
    "\n",
    "        self.conv_layer = Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode)\n",
    "        self.kernel_size = self.conv_layer.kernel_size\n",
    "\n",
    "        # small addition to avoid division by zero\n",
    "        self.delta = 1e-3\n",
    "\n",
    "        #Frequency\n",
    "        self.freq = Parameter(\n",
    "            (math.pi / 2)\n",
    "            * math.sqrt(2)\n",
    "            ** (-torch.randint(0, 5, (out_channels, in_channels))).type(torch.Tensor),\n",
    "            requires_grad=True,\n",
    "        )\n",
    "        #Theta\n",
    "        self.theta = Parameter(\n",
    "            (math.pi / 8)\n",
    "            * torch.randint(0, 8, (out_channels, in_channels)).type(torch.Tensor),\n",
    "            requires_grad=True,\n",
    "        )\n",
    "        #Sigma\n",
    "        self.sigma = Parameter(math.pi / self.freq, requires_grad=True)\n",
    "\n",
    "        #Psi\n",
    "        self.psi = Parameter(\n",
    "            math.pi * torch.rand(out_channels, in_channels), requires_grad=True\n",
    "        )\n",
    "\n",
    "        self.x0 = Parameter(\n",
    "            torch.ceil(torch.Tensor([self.kernel_size[0] / 2]))[0], requires_grad=False\n",
    "        )\n",
    "        self.y0 = Parameter(\n",
    "            torch.ceil(torch.Tensor([self.kernel_size[1] / 2]))[0], requires_grad=False\n",
    "        )\n",
    "\n",
    "        self.y, self.x = torch.meshgrid(\n",
    "            [\n",
    "                torch.linspace(-self.x0 + 1, self.x0 + 0, self.kernel_size[0]),\n",
    "                torch.linspace(-self.y0 + 1, self.y0 + 0, self.kernel_size[1]),\n",
    "            ]\n",
    "        )\n",
    "        self.y = Parameter(self.y.clone())\n",
    "        self.x = Parameter(self.x.clone())\n",
    "\n",
    "        self.weight = Parameter(\n",
    "            torch.empty(self.conv_layer.weight.shape, requires_grad=True),\n",
    "            requires_grad=True,\n",
    "        )\n",
    "\n",
    "        self.register_parameter(\"freq\", self.freq)\n",
    "        self.register_parameter(\"theta\", self.theta)\n",
    "        self.register_parameter(\"sigma\", self.sigma)\n",
    "        self.register_parameter(\"psi\", self.psi)\n",
    "        self.register_parameter(\"x_shape\", self.x0)\n",
    "        self.register_parameter(\"y_shape\", self.y0)\n",
    "        self.register_parameter(\"y_grid\", self.y)\n",
    "        self.register_parameter(\"x_grid\", self.x)\n",
    "        self.register_parameter(\"weight\", self.weight)\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        if self.training:\n",
    "            self.calculate_weights()\n",
    "            self.is_calculated = False\n",
    "        if not self.training:\n",
    "            if not self.is_calculated:\n",
    "                self.calculate_weights()\n",
    "                self.is_calculated = True\n",
    "        return self.conv_layer(input_tensor)\n",
    "\n",
    "    def calculate_weights(self):\n",
    "        for i in range(self.conv_layer.out_channels):\n",
    "            for j in range(self.conv_layer.in_channels):\n",
    "                sigma = self.sigma[i, j].expand_as(self.y) \n",
    "                freq = self.freq[i, j].expand_as(self.y) \n",
    "                theta = self.theta[i, j].expand_as(self.y) \n",
    "                psi = self.psi[i, j].expand_as(self.y) \n",
    "\n",
    "                rotx = self.x * torch.cos(theta) + self.y * torch.sin(theta)\n",
    "                roty = -self.x * torch.sin(theta) + self.y * torch.cos(theta)\n",
    "\n",
    "                g = torch.exp(\n",
    "                    -0.5 * ((rotx ** 2 + roty ** 2) / (sigma + self.delta) ** 2)\n",
    "                )\n",
    "                g = g * torch.cos(freq * rotx + psi)\n",
    "                g = g / (2 * math.pi * sigma ** 2)\n",
    "                self.conv_layer.weight.data[i, j] = g\n",
    "\n",
    "    def _forward_unimplemented(self, *inputs: Any):\n",
    "        \"\"\"\n",
    "        code checkers makes implement this method,\n",
    "        looks like error in PyTorch\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "        \n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = torch.tensor([x2.size()[2] - x1.size()[2]])\n",
    "        diffX = torch.tensor([x2.size()[3] - x1.size()[3]])\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class filt_cat(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x1, x2):     \n",
    "\n",
    "        # input is CHW\n",
    "        diffY = torch.tensor([x2.size()[2] - x1.size()[2]])\n",
    "        diffX = torch.tensor([x2.size()[3] - x1.size()[3]])\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return x;\n",
    "\n",
    "class SNP_Net(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(SNP_Net, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.g0 = GaborConv2d(n_channels, n_channels, kernel_size=(96, 96))\n",
    "        self.fc = filt_cat(n_channels, 2*n_channels)\n",
    "        self.inc = DoubleConv(2*n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 512)\n",
    "        self.up1 = Up(1024, 256, bilinear)\n",
    "        self.up2 = Up(512, 128, bilinear)\n",
    "        self.up3 = Up(256, 64, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        f = self.g0(x)\n",
    "        x0 = self.fc(f,x);\n",
    "        x1 = self.inc(x0)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        x = self.outc(x)\n",
    "        m = nn.Softmax(dim=1)\n",
    "        logits = m(x)\n",
    "        return logits\n",
    "    \n",
    "    \n",
    "class AAR_Net(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(AAR_Net, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "\n",
    "        self.g0 = GaborConv2d(n_channels, n_channels, kernel_size=(144, 144))\n",
    "\n",
    "        \n",
    "        self.fc = filt_cat(n_channels, 2*n_channels)\n",
    "        self.inc = DoubleConv(2*n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 512)\n",
    "        self.up1 = Up(1024, 256, bilinear)\n",
    "        self.up2 = Up(512, 128, bilinear)\n",
    "        self.up3 = Up(256, 64, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        f = self.g0(x)\n",
    "        x0 = self.fc(f,x);\n",
    "        x1 = self.inc(x0)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        x = self.outc(x)\n",
    "        m = nn.Softmax(dim=1)\n",
    "        logits = m(x)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09aafead-92a6-410c-86ae-9d0342c71da3",
   "metadata": {},
   "source": [
    "Gaussian Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f5068c-9ed4-406f-acdd-1d633af4575c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fspecial_gauss(size, sigma):\n",
    "\n",
    "    \"\"\"Function to mimic the 'fspecial' gaussian MATLAB function\n",
    "    \"\"\"\n",
    "\n",
    "    x, y = np.mgrid[-size//2 + 1:size//2 + 1, -size//2 + 1:size//2 + 1]\n",
    "    g = np.exp(-((x**2 + y**2)/(2.0*sigma**2)))\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7145740-e0a3-4b36-aa4b-05668346371b",
   "metadata": {},
   "source": [
    "Find Branchpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044e8aa7-2b7c-4ad5-9f6f-01490f18b002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skeleton_branchpoints(skel):\n",
    "    # Make our input nice, possibly necessary.\n",
    "    skel = skel.copy()\n",
    "    skel[skel!=0] = 1\n",
    "    skel = np.uint8(skel)\n",
    "\n",
    "    # Apply the convolution.\n",
    "    kernel = np.uint8([[1,  1, 1],\n",
    "                       [1, 10, 1],\n",
    "                       [1,  1, 1]])\n",
    "    src_depth = -1\n",
    "    filtered = cv2.filter2D(skel,src_depth,kernel)\n",
    "\n",
    "\n",
    "    out = np.zeros_like(skel)\n",
    "    out[np.where(filtered>12)] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6eb387-e848-4972-9f1a-f108c76fe745",
   "metadata": {},
   "source": [
    "Find Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad40790-1f7d-49c3-8110-f5a5b7da2f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skeleton_endpoints(skel):\n",
    "    # Make our input nice, possibly necessary.\n",
    "    skel = skel.copy()\n",
    "    skel[skel!=0] = 1\n",
    "    skel = np.uint8(skel)\n",
    "    \n",
    "    skel = np.pad(skel, (1, 1), 'constant', constant_values=(0, 0))\n",
    "\n",
    "    # Apply the convolution.\n",
    "    kernel = np.uint8([[1,  1, 1],\n",
    "                       [1, 10, 1],\n",
    "                       [1,  1, 1]])\n",
    "    src_depth = -1\n",
    "    filtered = cv2.filter2D(skel,src_depth,kernel)\n",
    "\n",
    "    # Look through to find the value of 11.\n",
    "    # This returns a mask of the endpoints, but if you\n",
    "    # just want the coordinates, you could simply\n",
    "    # return np.where(filtered==11)\n",
    "    out = np.zeros_like(skel)\n",
    "    out[np.where(filtered==11)] = 1\n",
    "    out = out[1:-1,1:-1]\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1637fc61-6630-477f-bbed-72c31b9231a0",
   "metadata": {},
   "source": [
    "Count Immune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427fc91b-c3d2-48a0-8869-0ea9ce5d50d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_immune_cells(mask, mask_AAR):\n",
    "\n",
    "    #Binary Mask of Immune Cells\n",
    "    binary = np.zeros(np.shape(mask)) \n",
    "    binary[np.where(mask==2)] = 1;\n",
    "\n",
    "\n",
    "    #Create Unique labels\n",
    "    islands = np.zeros(np.shape(binary))              \n",
    "    structure = np.ones((3, 3), dtype=int) \n",
    "    labeled, ncomponents = label(binary, structure)\n",
    "    labeled = labeled*binary;\n",
    "\n",
    "    #Count Immune Cells\n",
    "    count = 0;\n",
    "    unique = np.unique(labeled)\n",
    "    for unique_label in unique:\n",
    "        if(unique_label!=0):\n",
    "            if(np.shape(np.where(labeled ==unique_label))[1]>9):\n",
    "                count = count + 1;    \n",
    "    \n",
    "\n",
    "    #Normalize by Area of SNP\n",
    "    count = count * np.size(mask_AAR)/np.shape(np.where(mask_AAR==1))[1] \n",
    "  \n",
    "    return count;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83ea498-5037-4ac6-90c4-12485f86d7ad",
   "metadata": {},
   "source": [
    "Count Neuromas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4e84e0-cfde-43d9-a302-088c56d2e42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_neuromas(mask, mask_AAR):\n",
    "\n",
    "    #Binary Mask of Neuromas\n",
    "    binary = np.zeros(np.shape(mask)) \n",
    "    binary[np.where(mask==3)] = 1;\n",
    "\n",
    "\n",
    "    #Create Unique labels\n",
    "    islands = np.zeros(np.shape(binary))              \n",
    "    structure = np.ones((3, 3), dtype=int) \n",
    "    labeled, ncomponents = label(binary, structure)\n",
    "    labeled = labeled*binary;\n",
    "\n",
    "    #Count Neuromas\n",
    "    count = 0;\n",
    "    unique = np.unique(labeled)\n",
    "    for unique_label in unique:\n",
    "        if(unique_label!=0):\n",
    "            if(np.shape(np.where(labeled ==unique_label))[1]>9):\n",
    "                count = count + 1;    \n",
    "    \n",
    "\n",
    "    #Normalize by Area of SNP\n",
    "    count = count * np.size(mask_AAR)/np.shape(np.where(mask_AAR==1))[1];\n",
    "  \n",
    "    return count;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef8508b-7dc6-46f3-af09-20e28020abe6",
   "metadata": {},
   "source": [
    "Count Junctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c224086b-facf-476c-bce3-be86ace80cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_junctions(mask, mask_AAR):\n",
    "    \n",
    "  \n",
    "    #Remove Holes\n",
    "    skel = skeletonize(mask==1);\n",
    "    invert_skel = skel==0;\n",
    "    invert_skel = np.array(morphology.remove_small_objects(invert_skel, 10)) \n",
    "    skel = np.abs(invert_skel-1)\n",
    "    \n",
    "    #Skeletonize\n",
    "    skel = skeletonize(skel)\n",
    "\n",
    "    #Remove Boundarys\n",
    "    skel[0,:] = 0;\n",
    "    skel[:,0] = 0;\n",
    "    skel[-1,:] = 0;\n",
    "    skel[:,-1] = 0;\n",
    "\n",
    "    \n",
    "    #Find Branch Points\n",
    "    branchpoints = skeleton_branchpoints(skel);\n",
    "    bp = np.array(np.where(branchpoints==1))\n",
    "    \n",
    "    #Iterate through Branch Points, Remove Unncessary Pixels \n",
    "    structure = np.ones((3, 3), dtype=int) \n",
    "    for j in range(0, np.shape(bp)[1],1):\n",
    "\n",
    "        #Box Around Branch Point\n",
    "        box = skel[int(bp[0,j])-1:int(bp[0,j])+2, int(bp[1,j])-1:int(bp[1,j])+2].copy()\n",
    "        \n",
    "        #Before Removing Center\n",
    "        labeled, ncomponents = label(box, structure)\n",
    "        \n",
    "        #After Removing Center\n",
    "        box[1,1] = 0;     \n",
    "        labeled, ncomponents_new = label(box, structure)   \n",
    "        \n",
    "        #If Unchanged, Remove Center\n",
    "        if(ncomponents ==ncomponents_new ):\n",
    "            skel[int(bp[0,j]), int(bp[1,j])] = 0;\n",
    "\n",
    "\n",
    "    #Find Endpoints        \n",
    "    endpoints = skeleton_endpoints(skel);\n",
    "    ep = np.array(np.where(endpoints==1));        \n",
    "            \n",
    "    #Separate Branches\n",
    "    branchpoints = skeleton_branchpoints(skel);\n",
    "    skel_sep = skel.copy();\n",
    "    skel_sep[np.where(branchpoints==1)] = 0;     \n",
    "    \n",
    "    \n",
    "    #Create Unique labels for Branches\n",
    "    labeled, ncomponents = label(skel_sep, structure)\n",
    "    labeled = labeled*skel_sep;\n",
    "    unique = np.unique(labeled)\n",
    "    \n",
    "    \n",
    "    #Iterate through Branches\n",
    "    for unique_label in unique:\n",
    "        if(unique_label!=0):\n",
    "            \n",
    "            #Current Branch\n",
    "            current = np.zeros(np.shape(labeled));\n",
    "            current[np.where(labeled==unique_label)] = 1;\n",
    "            \n",
    "            \n",
    "            #If Current Branch Contains Endpoint\n",
    "            summation= np.sum(np.multiply(current,endpoints))       \n",
    "            if(np.shape(np.where(labeled==unique_label))[1]<10 and summation>0):\n",
    "                \n",
    "                #Remove Small Branches\n",
    "                skel[np.where(labeled==unique_label)] = 0;\n",
    "\n",
    "\n",
    "    #Remove  Spurs \n",
    "    branchpoints = skeleton_branchpoints(skel);  \n",
    "    skel[np.where(branchpoints ==1)] = 0;    \n",
    "    struct1 = ndimage.generate_binary_structure(2, 2)\n",
    "    skel = ndimage.binary_dilation(skel , structure=struct1)\n",
    "    skel = skeletonize(skel)\n",
    "\n",
    "\n",
    "    #Count Branchpoints\n",
    "    branchpoints = skeleton_branchpoints(skel); \n",
    "    labeled, ncomponents = label(branchpoints, structure)\n",
    "    labeled = labeled*branchpoints;\n",
    "    count = np.shape(np.unique(labeled))[0];\n",
    "\n",
    "    #Normalize by Area of SNP\n",
    "    count = count * np.size(mask_AAR)/np.shape(np.where(mask_AAR==1))[1];\n",
    "       \n",
    "\n",
    "    return count;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6232aa-26c8-450d-ad74-8420ef835a66",
   "metadata": {},
   "source": [
    "Nerve Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718a0220-fb57-45b9-894d-1df5da37c277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_nerve_density(mask, mask_AAR):\n",
    "\n",
    "    #Find Nerve\n",
    "    nerve = np.shape(np.where(mask==1))[1]\n",
    "\n",
    "    \n",
    "    #Nerve Density\n",
    "    total = np.size(mask)\n",
    "    density = round(400*400*(nerve/total))\n",
    "\n",
    "    #Normalize by Area of SNP\n",
    "    density = density * np.size(mask_AAR)/np.shape(np.where(mask_AAR==1))[1];\n",
    "\n",
    "    return density;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6269c65-f5ef-4582-b152-035fe4821a2a",
   "metadata": {},
   "source": [
    "Nerve Thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fae764-6074-4a21-bd6b-fe4d3f373836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_nerve_thickness(mask):\n",
    " \n",
    "    #Skeletonized Nerve\n",
    "    skel = skeletonize(mask==1);\n",
    "    skel = np.shape(np.where(skel==1))[1];\n",
    "\n",
    "    #Find Nerve \n",
    "    nerve = np.shape(np.where(mask==1))[1]\n",
    "\n",
    "\n",
    "    #Nerve Thickness\n",
    "    length = np.sqrt(np.size(mask));\n",
    "    thickness = (nerve/skel) *(400/length);\n",
    "\n",
    "    return thickness;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a877151a-e1ff-4222-8dae-d44ee61ce996",
   "metadata": {},
   "source": [
    "Nerve Tortuosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718abd49-2fab-4d0f-9f6a-d032db973850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_nerve_tortuosity(mask):\n",
    "    \n",
    "    \n",
    "    skel = skeletonize(mask==1);\n",
    "    branchpoints = skeleton_branchpoints(skel);\n",
    "    skel[np.where(branchpoints==1)] = 0;\n",
    "\n",
    "    #Initialize RMS Sum\n",
    "    tau_C_Sum = 0;\n",
    "    tau_L_Sum = 0;\n",
    "    tau_CL_Sum = 0;\n",
    "\n",
    "    #Iterate through objects of length greater than 1\n",
    "    islands = np.zeros(np.shape(skel))              \n",
    "    structure = np.ones((3, 3), dtype=int) \n",
    "    labeled, ncomponents = label(skel, structure)\n",
    "    labeled = labeled*skel;\n",
    "    unique = np.unique(labeled)\n",
    "    for unique_label in unique:\n",
    "        if(unique_label!=0):\n",
    "            if(np.shape(np.where(labeled==unique_label))[1]>3):\n",
    "\n",
    "                #Find Endpoints\n",
    "                current_branch = np.zeros(np.shape(skel));\n",
    "                current_branch[np.where(labeled==unique_label)] = 1;\n",
    "                endpoints = skeleton_endpoints(current_branch);\n",
    "                ep = np.where(endpoints==1);\n",
    "                y_pos = ep[0];\n",
    "                x_pos = ep[1]\n",
    "\n",
    "                #Skip Issues\n",
    "                if(np.shape(np.where(endpoints==1))[1]==0):\n",
    "                    continue;\n",
    "                \n",
    "\n",
    "                #Find Straight-Line Distance\n",
    "                Lx = np.sqrt(np.power(y_pos[0]-y_pos[1],2)+np.power(x_pos[0]-x_pos[1],2));\n",
    "\n",
    "                #Pixels in Branch\n",
    "                locs = np.where(current_branch==1);\n",
    "                y_locs = locs[0];\n",
    "                x_locs = locs[1];\n",
    "\n",
    "                #Order Pixels in branch\n",
    "                distances = np.sqrt(np.power(y_locs-y_pos[0],2) + np.power(x_locs-x_pos[0],2));\n",
    "                idx = np.argsort(distances);\n",
    "                y_locs = y_locs[idx];\n",
    "                x_locs = x_locs[idx];\n",
    "\n",
    "\n",
    "\n",
    "                Lc=0;\n",
    "                tau_C=0;\n",
    "                for a in range(1,np.shape(y_locs)[0]):\n",
    "                    #Calculate First Differential\n",
    "                    first_x = x_locs[a]-x_locs[a-1];\n",
    "                    first_y = y_locs[a]-y_locs[a-1];\n",
    "\n",
    "\n",
    "                    if a>1:\n",
    "                      \n",
    "                        #Calculate Second Differential\n",
    "                        prev_x = x_locs[a-1]-x_locs[a-2];\n",
    "                        prev_y = y_locs[a-1]-y_locs[a-2];\n",
    "                        second_x = first_x-prev_x;\n",
    "                        second_y = first_y-prev_y;\n",
    "                        Ki = ((first_x*second_y)-(second_x*first_y))/np.power(np.power(first_x,2)+np.power(first_y,2),(3/2));\n",
    "                    else:\n",
    "                        Ki=0\n",
    "\n",
    "                    #Calculate Various Measures\n",
    "                    Lc = Lc + np.sqrt(np.power(first_x,2)+np.power(first_y,2));\n",
    "                    tau_C = tau_C + abs(Ki);\n",
    "\n",
    "                #Weight Different measures\n",
    "                tau_L = Lc/Lx;\n",
    "                tau_CL = tau_C/Lc;\n",
    "                tau_C_Sum = tau_C_Sum + tau_C*np.shape(np.where(labeled==unique_label))[1];\n",
    "                tau_L_Sum = tau_L_Sum + tau_L*np.shape(np.where(labeled==unique_label))[1];\n",
    "                tau_CL_Sum = tau_CL_Sum + tau_CL*np.shape(np.where(labeled==unique_label))[1];\n",
    "\n",
    "\n",
    "\n",
    "    #Normalize by Skel\n",
    "    skel_count = np.shape(np.where(skel==1))\n",
    "    skel_count = skel_count[1];  \n",
    "\n",
    "\n",
    "    #Add to Tortuosity List\n",
    "    return tau_C_Sum/skel_count;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c04837-1d8a-4098-879e-c08646426181",
   "metadata": {},
   "source": [
    "Fix Mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669cd0fa-9d27-4a6c-99e1-477297077008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_mixture_1(prediction, class_1, class_2):\n",
    "\n",
    "    \n",
    "    # Class Locations\n",
    "    binary = np.zeros(np.shape(prediction)) \n",
    "    binary[np.where(prediction==class_1)] = 1;\n",
    "    binary[np.where(prediction==class_2)] = 1;\n",
    "    \n",
    "    #Create Labeled Islands\n",
    "    islands = np.zeros(np.shape(prediction))              \n",
    "    structure = np.ones((3, 3), dtype=int) \n",
    "    labeled, ncomponents = label(binary, structure)\n",
    "    labeled = labeled*binary;\n",
    "    \n",
    "    #Iterate through Islands\n",
    "    unique = np.unique(labeled)\n",
    "    for unique_label in unique:\n",
    "        if(unique_label!=0):\n",
    "            \n",
    "            #If more than one class in island\n",
    "            if(np.unique(prediction[np.where(labeled==unique_label)]).size >1):\n",
    "                \n",
    "                                              \n",
    "                #More abundant class dominates\n",
    "                count_1 = np.shape(np.where(prediction[np.where(labeled==unique_label)]==class_1))[1];\n",
    "                count_2 = np.shape(np.where(prediction[np.where(labeled==unique_label)]==class_2))[1];\n",
    "                if( count_1>count_2):\n",
    "                    prediction[np.where(labeled==unique_label)] = class_1\n",
    "                else:\n",
    "                    prediction[np.where(labeled==unique_label)] = class_2\n",
    "                    \n",
    "    return prediction;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a27fb35-5d79-4cf9-85ad-49e91d462702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_mixture_2(prediction, class_1, class_2):\n",
    "\n",
    "    \n",
    "    # Class Locations\n",
    "    binary = np.zeros(np.shape(prediction)) \n",
    "    binary[np.where(prediction==class_1)] = 1;\n",
    "    binary[np.where(prediction==class_2)] = 1;\n",
    "    \n",
    "    #Create Labeled Islands\n",
    "    islands = np.zeros(np.shape(prediction))              \n",
    "    structure = np.ones((3, 3), dtype=int) \n",
    "    labeled, ncomponents = label(binary, structure)\n",
    "    labeled = labeled*binary;\n",
    "    \n",
    "    #Iterate through Islands\n",
    "    unique = np.unique(labeled)\n",
    "    for unique_label in unique:\n",
    "        if(unique_label!=0):\n",
    "            \n",
    "            #If more than one class in island\n",
    "            if(np.unique(prediction[np.where(labeled==unique_label)]).size >1):\n",
    "                \n",
    "                                              \n",
    "                #More abundant class dominates\n",
    "                count_1 = np.shape(np.where(prediction[np.where(labeled==unique_label)]==class_1))[1];\n",
    "                count_2 = np.shape(np.where(prediction[np.where(labeled==unique_label)]==class_2))[1];\n",
    "                if( count_1<count_2):\n",
    "                    prediction[np.where(labeled==unique_label)] = class_2\n",
    "                    \n",
    "    return prediction;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7176aa-84b6-48e7-88b5-1f3e086ade65",
   "metadata": {},
   "source": [
    "Fix Class within Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0261494e-38e8-4833-89f4-2563b2b9e3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_inner(prediction):\n",
    "\n",
    "    #Iterate through Classes\n",
    "    for class_outer in range(1,4):\n",
    "\n",
    "        # Class Locations\n",
    "        binary = np.zeros(np.shape(prediction)) \n",
    "        binary[np.where(prediction==class_outer)] = 1;\n",
    "        \n",
    "        \n",
    "        #Fill Holes\n",
    "        binary = ndimage.binary_fill_holes(binary).astype(int)\n",
    "        binary[np.where(prediction==class_outer)] = 0;\n",
    "        \n",
    "        #Create Labeled Islands\n",
    "        structure = np.ones((3, 3), dtype=int) \n",
    "        labeled, ncomponents = label(binary, structure)\n",
    "        labeled = labeled*binary;\n",
    "        \n",
    "        \n",
    "        #Iterate through Islands\n",
    "        unique = np.unique(labeled)\n",
    "        for unique_label in unique:\n",
    "            if(unique_label!=0):    \n",
    "                \n",
    "                #If it doesn't contain background\n",
    "                if(0 not in np.unique(prediction[np.where(labeled==unique_label)])):\n",
    "                    prediction[np.where(labeled==unique_label)] = class_outer;\n",
    "    \n",
    "    return prediction;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6ed172-0317-402d-a174-3a7a05bce722",
   "metadata": {},
   "source": [
    "Remove Small Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed71067-54bb-4b58-a8a4-7a1c0ca5dc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_small(prediction):\n",
    "\n",
    "    #Iterate through Classes\n",
    "    for current_class in range(1,4):\n",
    "\n",
    "        # Class Locations\n",
    "        binary = np.zeros(np.shape(prediction)) \n",
    "        binary[np.where(prediction==current_class)] = 1;\n",
    "        \n",
    "        \n",
    "        #Create Labeled Islands\n",
    "        islands = np.zeros(np.shape(prediction))              \n",
    "        structure = np.ones((3, 3), dtype=int) \n",
    "        labeled, ncomponents = label(binary, structure)\n",
    "        labeled = labeled*binary;\n",
    "\n",
    "        #Iterate through Islands\n",
    "        unique = np.unique(labeled)\n",
    "        for unique_label in unique:\n",
    "            if(unique_label!=0): \n",
    "                \n",
    "                if(np.shape(np.where(labeled ==unique_label))[1]<8):\n",
    "                    prediction[np.where(labeled==unique_label)] = 0;\n",
    "    \n",
    "    return prediction;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766fada8-9d05-4817-9aa6-59cea72f1b4d",
   "metadata": {},
   "source": [
    "Test AAR-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388a4537-f2a9-443f-85b0-e454b40895bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_AAR_net(SNP, torch_path, Experiment_Name, Model_Name, tissues, channels):\n",
    "    \n",
    " \n",
    "    #Weight\n",
    "    weight_kernel = fspecial_gauss(192, 20);\n",
    "    \n",
    "    #Load Models\n",
    "    for g in range(0,5):\n",
    "\n",
    "        validation = np.load(torch_path  +'Validation_Dice_'+  Model_Name +'_' + Experiment_Name + '_Group_' + str(g)  +'.npy').squeeze();       \n",
    "        epoch = np.argmax(validation[0,40:]) + 40;\n",
    "\n",
    "\n",
    "        #Model\n",
    "        if(g==0):\n",
    "            net_0 = AAR_Net(n_channels=channels, n_classes=tissues);\n",
    "            net_0.load_state_dict(torch.load(torch_path + Model_Name + '_' + Experiment_Name + '_Group_' + str(g) + '_Epoch_' +str(epoch+1) +'.pth', map_location=device));\n",
    "            net_0.to(device=device);  \n",
    "            net_0.eval();\n",
    "        elif(g==1):\n",
    "            net_1 =AAR_Net(n_channels=channels, n_classes=tissues);\n",
    "            net_1.load_state_dict(torch.load(torch_path + Model_Name + '_' + Experiment_Name + '_Group_' + str(g) + '_Epoch_' +str(epoch+1) +'.pth', map_location=device));\n",
    "            net_1.to(device=device);  \n",
    "            net_1.eval()        \n",
    "        elif(g==2):\n",
    "            net_2 =AAR_Net(n_channels=channels, n_classes=tissues);\n",
    "            net_2.load_state_dict(torch.load(torch_path + Model_Name + '_' + Experiment_Name + '_Group_' + str(g) + '_Epoch_' +str(epoch+1) +'.pth', map_location=device));\n",
    "            net_2.to(device=device);  \n",
    "            net_2.eval()           \n",
    "        elif(g==3):\n",
    "            net_3 = AAR_Net(n_channels=channels, n_classes=tissues);\n",
    "            net_3.load_state_dict(torch.load(torch_path + Model_Name + '_' + Experiment_Name + '_Group_' + str(g) + '_Epoch_' +str(epoch+1) +'.pth', map_location=device));\n",
    "            net_3.to(device=device);  \n",
    "            net_3.eval()  \n",
    "        elif(g==4):\n",
    "            net_4 = AAR_Net(n_channels=channels, n_classes=tissues); \n",
    "            net_4.load_state_dict(torch.load(torch_path + Model_Name + '_' + Experiment_Name + '_Group_' + str(g) + '_Epoch_' +str(epoch+1) +'.pth', map_location=device));\n",
    "            net_4.to(device=device);  \n",
    "            net_4.eval()  \n",
    " \n",
    "\n",
    "\n",
    "    #Iterate through Images\n",
    "    AAR_Masks = [];\n",
    "    for idx in range(0, np.shape(SNP)[0]):\n",
    "\n",
    "\n",
    "        #Select Image\n",
    "        img = SNP[idx, :,:].copy();\n",
    "\n",
    "        #Initialize\n",
    "        collective = np.zeros((tissues,384,384));\n",
    "        weight = np.zeros((tissues,384,384));\n",
    "         \n",
    "            \n",
    "        #Iterate\n",
    "        for row in range(0,200,8):\n",
    "            for col in range(0,200,8):\n",
    "\n",
    "                #Select Window\n",
    "                cropped_img = img[row:row+192,col:col+192].copy();\n",
    "\n",
    "\n",
    "\n",
    "                #Normalize Window\n",
    "                cropped_img = (cropped_img - np.min(cropped_img))/(np.max(cropped_img) - np.min(cropped_img))\n",
    "                cropped_img = cropped_img - 0.5;\n",
    "\n",
    "                #Flip\n",
    "                cropped_img_0 = cropped_img.copy();\n",
    "                cropped_img_1 = np.fliplr(cropped_img).copy();\n",
    "                cropped_img_2 = np.flipud(cropped_img).copy();\n",
    "                cropped_img_3 = np.fliplr(np.flipud(cropped_img).copy()).copy();\n",
    "\n",
    "                #Expand Dim\n",
    "                cropped_img_0 = np.expand_dims(cropped_img_0,axis = 0);\n",
    "                cropped_img_1 = np.expand_dims(cropped_img_1,axis = 0);\n",
    "                cropped_img_2 = np.expand_dims(cropped_img_2,axis = 0);\n",
    "                cropped_img_3 = np.expand_dims(cropped_img_3,axis = 0);\n",
    "\n",
    "                #Concatenate\n",
    "                cropped_img = np.concatenate((cropped_img_0, cropped_img_1, cropped_img_2, cropped_img_3), 0);\n",
    "                cropped_img = np.reshape(cropped_img, (-1,1,192,192))\n",
    "\n",
    "\n",
    "                #Pre-process the Input Image \n",
    "                input_img = torch.from_numpy(cropped_img).to(device=device, dtype=torch.float32);\n",
    "\n",
    "\n",
    "                with torch.no_grad():\n",
    "\n",
    "                    #Predict the Mask                         \n",
    "                    output = net_0(input_img) + net_1(input_img) + net_2(input_img) + net_3(input_img) + net_4(input_img);\n",
    "\n",
    "\n",
    "                    #Extract Outputs  \n",
    "                    output = output.cpu().detach().numpy();\n",
    "                    output_0 = output[0].squeeze();\n",
    "                    output_1 = output[1].squeeze();\n",
    "                    output_2 = output[2].squeeze();\n",
    "                    output_3 = output[3].squeeze();                    \n",
    "\n",
    "\n",
    "                    #Flip\n",
    "                    output_1[0] = np.fliplr(output_1[0]).copy();\n",
    "                    output_1[1] = np.fliplr(output_1[1]).copy();\n",
    "                    output_1[2] = np.fliplr(output_1[2]).copy();\n",
    "                    output_2[0] = np.flipud(output_2[0]).copy();\n",
    "                    output_2[1] = np.flipud(output_2[1]).copy();\n",
    "                    output_2[2] = np.flipud(output_2[2]).copy();\n",
    "                    output_3[0] = np.fliplr(np.flipud(output_3[0]).copy()).copy();\n",
    "                    output_3[1] = np.fliplr(np.flipud(output_3[1]).copy()).copy();\n",
    "                    output_3[2] = np.fliplr(np.flipud(output_3[2]).copy()).copy();\n",
    "\n",
    "\n",
    "                    #Multiply by Weight\n",
    "                    mult_output_0 = np.multiply(softmax(output_0,axis = 0),weight_kernel);\n",
    "                    mult_output_1 = np.multiply(softmax(output_1,axis = 0),weight_kernel);\n",
    "                    mult_output_2 = np.multiply(softmax(output_2,axis = 0),weight_kernel);\n",
    "                    mult_output_3 = np.multiply(softmax(output_3,axis = 0),weight_kernel);\n",
    "\n",
    "                    #Add to Collective\n",
    "                    collective[:,row:row+192,col:col+192] += mult_output_0 + mult_output_1 + mult_output_2 + mult_output_3;\n",
    "                    weight[:,row:row+192,col:col+192] +=4*weight_kernel ;\n",
    "\n",
    "        #Divide by Count\n",
    "        collective = np.divide(collective, weight);\n",
    "        max_mask = np.argmax(collective, axis = 0);\n",
    "        \n",
    "        #Append Masks\n",
    "        AAR_Masks.append(max_mask);\n",
    "        \n",
    "    \n",
    "    AAR_Masks = np.array(AAR_Masks)\n",
    "    return AAR_Masks;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f19d8a4-61c0-4e4a-9f81-bf7ed976cee4",
   "metadata": {},
   "source": [
    "Test SNP-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5a3c14-981a-48c7-9c29-45e7471b19a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_SNP_net(SNP, masks_AAR, g, t, torch_path, Experiment_Name, Model_Name, tissues, channels):\n",
    "    \n",
    " \n",
    "\n",
    "\n",
    "    #Correct Applanation Artifact Removal\n",
    "    masks_AAR_binary = (masks_AAR==0);\n",
    "    masks_AAR_binary = masks_AAR_binary *1.0;\n",
    "    \n",
    "    #Weight\n",
    "    weight_kernel = fspecial_gauss(96, 5);\n",
    "    \n",
    "        \n",
    "    #Initialize\n",
    "    immune_counts = np.zeros((np.shape(SNP)[0], 1));\n",
    "    neuroma_counts = np.zeros((np.shape(SNP)[0], 1));\n",
    "    junction_counts = np.zeros((np.shape(SNP)[0], 1));\n",
    "    nerve_densities = np.zeros((np.shape(SNP)[0], 1));\n",
    "    nerve_thicknesses = np.zeros((np.shape(SNP)[0], 1));  \n",
    "    nerve_tortuosities = np.zeros((np.shape(SNP)[0], 1));   \n",
    "        \n",
    "   \n",
    "   \n",
    "    #Load Network\n",
    "    validation = np.load(torch_path  +'Validation_Dice_'+  Model_Name +'_' + Experiment_Name +'_Group_' + str(t) +'_' + str(g) + '.npy').squeeze();    \n",
    "    epoch = np.argmax(validation[0,60:]) + 60;\n",
    "    net = SNP_Net(n_channels=channels, n_classes=tissues);\n",
    "    net.load_state_dict(torch.load(torch_path + Model_Name + '_' + Experiment_Name + '_Group_' + str(t) +'_' + str(g) + '_Epoch_' +str(epoch+1) +'.pth', map_location=device));\n",
    "    net.to(device=device);  \n",
    "    net.eval();                        \n",
    "\n",
    "\n",
    "    #Iterate through Images\n",
    "    masks = [];\n",
    "    for idx in range(0, np.shape(SNP)[0]):\n",
    "\n",
    "        \n",
    "        #Select Image\n",
    "        img = SNP[idx, :,:].copy();\n",
    "        mask_AAR = masks_AAR_binary[idx, :,:].copy();\n",
    "\n",
    "        #Normalize\n",
    "        img = img/np.max(img)\n",
    "        img = img - 0.5;    \n",
    "\n",
    "        #Initialize\n",
    "        collective = np.zeros((tissues,384,384));\n",
    "        weight = np.zeros((tissues,384,384));\n",
    "\n",
    "\n",
    "        #Iterate through Patches\n",
    "        for row in range(0,324,36):\n",
    "            for col in range(0,324,36):\n",
    "\n",
    "                for flip_idx in range(0,4):\n",
    "\n",
    "                    #Select Window\n",
    "                    cropped_img = img[row:row+96,col:col+96].copy();\n",
    "\n",
    "\n",
    "\n",
    "                     #Flip Image\n",
    "                    if(flip_idx >1):\n",
    "                        cropped_img = np.fliplr(cropped_img).copy();\n",
    "                    if(flip_idx ==1 or flip_idx ==3):\n",
    "                        cropped_img = np.flipud(cropped_img).copy();               \n",
    "                    cropped_img = np.expand_dims(cropped_img,axis = 0);\n",
    "\n",
    "                    #Cast to Torch\n",
    "                    input_img = torch.from_numpy(cropped_img).unsqueeze(0).to(device=device, dtype=torch.float32);\n",
    "\n",
    "\n",
    "                    with torch.no_grad():\n",
    "\n",
    "                        #Predict the Mask                                         \n",
    "                        output = net(input_img);\n",
    "\n",
    "\n",
    "                        output = output.cpu().detach().numpy().squeeze();\n",
    "\n",
    "                        #Multiply with Gaussian Weight\n",
    "                        mult_output = np.multiply(softmax(output,axis = 0),weight_kernel);   \n",
    "\n",
    "                        #Flip\n",
    "                        flip_output = mult_output.copy()\n",
    "                        if(flip_idx >1):\n",
    "                            mult_output[0] = np.fliplr(mult_output[0]).copy();\n",
    "                            mult_output[1] = np.fliplr(mult_output[1]).copy();\n",
    "                            mult_output[2] = np.fliplr(mult_output[2]).copy();\n",
    "                            mult_output[3] = np.fliplr(mult_output[3]).copy();\n",
    "                        if(flip_idx ==1 or flip_idx ==3):\n",
    "                            mult_output[0] = np.flipud(mult_output[0]).copy();\n",
    "                            mult_output[1] = np.flipud(mult_output[1]).copy();\n",
    "                            mult_output[2] = np.flipud(mult_output[2]).copy();\n",
    "                            mult_output[3] = np.flipud(mult_output[3]).copy();\n",
    "\n",
    "                        #Add to Collective\n",
    "                        collective[:,row:row+96,col:col+96] += mult_output\n",
    "                        weight[:,row:row+96,col:col+96] +=weight_kernel ;\n",
    "\n",
    "\n",
    "        #Divide by Count\n",
    "        collective = np.divide(collective, weight);\n",
    "        prediction = np.argmax(collective, axis = 0);\n",
    "\n",
    "\n",
    "        #Applanatin Artifact Removal\n",
    "        prediction = prediction*mask_AAR;\n",
    "\n",
    "\n",
    "        #Fix Mixture\n",
    "        prediction = fix_mixture_1(prediction, 2, 3);\n",
    "        prediction = fix_mixture_2(prediction, 1, 2);\n",
    "\n",
    "        #Fix Classes within Class\n",
    "        prediction = fix_inner(prediction);\n",
    "\n",
    "\n",
    "        #Remove Small Objects\n",
    "        prediction = remove_small(prediction);\n",
    "\n",
    "        #Append Masks\n",
    "        masks.append(prediction)\n",
    "        \n",
    "        #Clinical Metrics: Automatic\n",
    "        immune_counts[idx,0] = count_immune_cells(prediction, mask_AAR);\n",
    "        neuroma_counts[idx,0] =  count_neuromas(prediction, mask_AAR); \n",
    "        junction_counts[idx,0] =  count_junctions(prediction, mask_AAR); \n",
    "        nerve_densities[idx,0] =  calculate_nerve_density(prediction, mask_AAR);\n",
    "        nerve_thicknesses[idx,0] =  calculate_nerve_thickness(prediction);\n",
    "        nerve_tortuosities[idx,0] =  calculate_nerve_tortuosity(prediction); \n",
    "\n",
    "        \n",
    "    \n",
    " \n",
    "    masks = np.array(masks);\n",
    "    return  masks, immune_counts, neuroma_counts, junction_counts, nerve_densities, nerve_thicknesses, nerve_tortuosities;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b0efec-4e63-45b0-b8c3-60c669311cbc",
   "metadata": {},
   "source": [
    "Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c69a25-3207-4b4e-be49-d1eeaf509dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cast to Cuda\n",
    "CUDA_VISIBLE_DEVICES=0\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "if cuda:\n",
    "    FloatTensor = torch.cuda.FloatTensor\n",
    "    LongTensor = torch.cuda.LongTensor\n",
    "else:\n",
    "    FloatTensor = torch.FloatTensor\n",
    "    LongTensor = torch.LongTensor\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56266c54-5ab6-4b13-b4bd-33c6222b47a3",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881b7fcd-09aa-45b7-b348-7fd0b04a958a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Specify Data Path and Save Path\n",
    "img_path = r'/hpc/group/viplab/zzz3/SNP_Segmentation/Files/Raw/New_Data/'\n",
    "\n",
    "# ---------------------\n",
    "#  Load Images\n",
    "# ---------------------\n",
    "\n",
    "\n",
    "#Iterate\n",
    "images = [];\n",
    "files = sorted(os.listdir(img_path))\n",
    "for fname in files:\n",
    "    \n",
    "    if(fname[0]=='.'):\n",
    "        continue;\n",
    "   \n",
    "    #Load Images\n",
    "    image = Image.open(os.path.join(img_path,fname)).convert('L');     \n",
    "    image = np.array(image.resize((384,384), PIL.Image.BILINEAR)).astype(np.float32)\n",
    "    images.append(image);\n",
    "    \n",
    "SNP = np.array(images);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3e687d-9ee1-4b73-9f5c-f38e912cadf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "#  Test AAR-Net\n",
    "# ---------------------\n",
    "\n",
    "#AAR-Net Parameters\n",
    "Experiment_Name = 'Original';\n",
    "Model_Name = 'AAR_Net';\n",
    "tissues = 3;\n",
    "channels = 1;\n",
    "torch_path = r'/hpc/group/viplab/zzz3/SNP_Segmentation/Files/Torch/AAR-Net/';\n",
    "\n",
    "\n",
    "#Test AAR-Net\n",
    "masks_AAR = test_AAR_net(SNP, torch_path, Experiment_Name, Model_Name, tissues, channels)\n",
    "\n",
    "\n",
    "# ---------------------\n",
    "#  Test SNP-Net\n",
    "# ---------------------\n",
    "\n",
    "#Parameters\n",
    "Experiment_Name = 'Original';\n",
    "Model_Name = 'SNP_Net';\n",
    "tissues = 4;\n",
    "channels = 1;\n",
    "torch_path = r'/hpc/group/viplab/zzz3/SNP_Segmentation/Files/Torch/SNP-Net/';\n",
    "\n",
    "#Best SNP-Net Model on all 207 SNP Images\n",
    "t = 11;\n",
    "g = 1;\n",
    "\n",
    "\n",
    "        \n",
    "#Test SNP-Net\n",
    "masks, immune_counts, neuroma_counts, junction_counts, nerve_densities, nerve_thicknesses, nerve_tortuosities = test_SNP_net(SNP, masks_AAR, g, t, torch_path, Experiment_Name, Model_Name, tissues, channels)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7037707f-735e-41bb-83aa-9126f588b812",
   "metadata": {},
   "source": [
    "Save Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b204ad6a-3525-4b98-9927-2920158fa665",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_path =  r'/hpc/group/viplab/zzz3/SNP_Segmentation/Files/Excel/';\n",
    "\n",
    "\n",
    "#Initialize\n",
    "current = datetime.now().strftime(\"%m_%d_%Y-%I_%M_%S_%p\")\n",
    "workbook = xlsxwriter.Workbook(excel_path + 'clinical_metrics_'+ current +'.xlsx')\n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "#Headers\n",
    "worksheet.write('A1', 'File Name')\n",
    "worksheet.write('B1', 'Nerve Density (um2/160,000 um2)')\n",
    "worksheet.write('C1', 'Average Nerve Thickness (um)')\n",
    "worksheet.write('D1', 'Average Nerve Segment Tortuosity')\n",
    "worksheet.write('E1', 'Junction Point Density (count/160,000 um2)')\n",
    "worksheet.write('F1', 'Neuroma Density (count/160,000 um2)')\n",
    "worksheet.write('G1', 'Immune Cell Density (count/160,000 um2)')\n",
    "\n",
    "\n",
    "idx = -1;\n",
    "for fname in files:\n",
    "    \n",
    "    if(fname[0]=='.'):\n",
    "        continue;\n",
    "    else:\n",
    "        idx = idx +1;\n",
    "        \n",
    "    nerve_density = round(nerve_densities[idx,0]);\n",
    "    nerve_thickness = round(nerve_thicknesses[idx,0],1);\n",
    "    nerve_tortuosity = round(nerve_tortuosities[idx,0],1);\n",
    "    junction_count = round(junction_counts[idx,0],1);\n",
    "    neuroma_count = round(neuroma_counts[idx,0],1);\n",
    "    immune_count = round(immune_counts[idx,0],1);\n",
    "    \n",
    "    \n",
    "    worksheet.write('A' + str(idx+2), fname)\n",
    "    worksheet.write('B' + str(idx+2), str(nerve_density))\n",
    "    worksheet.write('C' + str(idx+2), str(nerve_thickness))\n",
    "    worksheet.write('D' + str(idx+2), str(nerve_tortuosity))\n",
    "    worksheet.write('E' + str(idx+2), str(junction_count))\n",
    "    worksheet.write('F' + str(idx+2), str(neuroma_count))\n",
    "    worksheet.write('G' + str(idx+2), str(immune_count))\n",
    "    \n",
    "    \n",
    "\n",
    "workbook.close()\n",
    "print('All Clinical Metrics inserted successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170e3a45-293f-4c45-bcae-5fb7f127537d",
   "metadata": {},
   "source": [
    "Plot and Save Results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bc39c2-dd08-4943-808f-4f82ab4c6a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = r'/hpc/group/viplab/zzz3/SNP_Segmentation/Files/Images/New_Data/'\n",
    "\n",
    "\n",
    "#Parameters\n",
    "Plot_Figures = True;\n",
    "Save_Figures = True;\n",
    "\n",
    "\n",
    "idx = -1;\n",
    "for fname in files:\n",
    "    \n",
    "    if(fname[0]=='.'):\n",
    "        continue;\n",
    "    else:\n",
    "        idx = idx +1; \n",
    "\n",
    "\n",
    "    mask_AAR = masks_AAR[idx,:,:].squeeze();\n",
    "    mask = masks[idx,:,:].squeeze();\n",
    "    img = SNP[idx,:,:].squeeze();\n",
    "    \n",
    "    \n",
    "    #Plot\n",
    "    if(Plot_Figures):\n",
    "\n",
    "        #Plot Original Image\n",
    "        plt.figure;\n",
    "        plt.title('Image')\n",
    "        plt.imshow(img,cmap='gray')\n",
    "        plt.show()        \n",
    "\n",
    "\n",
    "    #Convert Mask to Color\n",
    "    color_new_mask_1 = np.zeros((384,384));\n",
    "    color_new_mask_2 = np.zeros((384,384));\n",
    "    color_new_mask_3 = np.zeros((384,384));\n",
    "    color_new_mask_1[np.where(mask_AAR==0)] = 255;\n",
    "    color_new_mask_2[np.where(mask_AAR==2)] = 255;\n",
    "    color_new_mask_3[np.where(mask_AAR==1)] = 255;\n",
    "    color_new_mask = np.zeros((384,384,3));\n",
    "    color_new_mask[:,:,0] = color_new_mask_1;\n",
    "    color_new_mask[:,:,1] = color_new_mask_3\n",
    "    color_new_mask[:,:,2] = color_new_mask_2;\n",
    "    color_new_mask = np.array(color_new_mask, dtype = 'uint8')\n",
    "\n",
    "    #Plot\n",
    "    if(Plot_Figures):\n",
    "\n",
    "        #Plot Mask\n",
    "        plt.figure;\n",
    "        plt.title('AAR-Net Segmentation')\n",
    "        plt.imshow(color_new_mask)\n",
    "        plt.show()  \n",
    "\n",
    "        \n",
    "    if(Save_Figures):\n",
    "        \n",
    "        #Fix fname\n",
    "        new_fname = fname;\n",
    "        new_fname = new_fname.replace('.png','');\n",
    "        new_fname = new_fname.replace('.jpg','');\n",
    "        new_fname = new_fname.replace('.gif','');\n",
    "        \n",
    "        \n",
    "        #Save\n",
    "        new_fname = new_fname + '_AAR_Seg.jpg';\n",
    "        save_img = Image.fromarray(color_new_mask);\n",
    "        save_img.save(save_path + new_fname)                   \n",
    "       \n",
    "    \n",
    "\n",
    "    #Convert Mask to Color\n",
    "    color_new_mask_1 = np.zeros((384,384));\n",
    "    color_new_mask_2 = np.zeros((384,384));\n",
    "    color_new_mask_3 = np.zeros((384,384));\n",
    "    color_new_mask_1[np.where(mask==1)] = 255;\n",
    "    color_new_mask_2[np.where(mask==3)] = 255;\n",
    "    color_new_mask_3[np.where(mask==2)] = 255;\n",
    "    color_new_mask = np.zeros((384,384,3));\n",
    "    color_new_mask[:,:,0] = color_new_mask_1;\n",
    "    color_new_mask[:,:,1] = color_new_mask_3\n",
    "    color_new_mask[:,:,2] = color_new_mask_2;\n",
    "    color_new_mask = np.array(color_new_mask, dtype = 'uint8')\n",
    "\n",
    "    #Plot\n",
    "    if(Plot_Figures):  \n",
    "\n",
    "        #Plot Mask\n",
    "        plt.figure;\n",
    "        plt.title('SNP-Net Segmentation')\n",
    "        plt.imshow(color_new_mask)\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "    if(Save_Figures):\n",
    "        \n",
    "        #Fix fname\n",
    "        new_fname = new_fname.replace('_AAR_Seg.jpg','');\n",
    "\n",
    "         \n",
    "        #Save\n",
    "        new_fname = new_fname + '_SNP_Seg.jpg';\n",
    "        save_img = Image.fromarray(color_new_mask);\n",
    "        save_img.save(save_path + new_fname)   \n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
