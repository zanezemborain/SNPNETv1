{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d72b5457-e77e-40cb-8430-f3e7332a378c",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ee9e9a-cb48-4547-8895-14fdc383ff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Python Packages\n",
    "import copy;\n",
    "from functools import reduce\n",
    "from glob import glob\n",
    "from glob import iglob\n",
    "import logging\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from operator import __add__\n",
    "import os\n",
    "from os.path import splitext\n",
    "from os import listdir\n",
    "import pandas as pd;\n",
    "from PIL import Image, ImageOps\n",
    "import PIL\n",
    "from random import randint\n",
    "import random;\n",
    "import sys\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from scipy.ndimage.measurements import label\n",
    "from scipy.special import softmax\n",
    "from skimage import exposure\n",
    "from skimage import feature\n",
    "from skimage import transform as tf\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.nn import Parameter\n",
    "from torch.nn.modules import Conv2d, Module\n",
    "from tqdm import tqdm\n",
    "from typing import Any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b3f3d6-01d9-447c-b3b1-cd28e4751f73",
   "metadata": {},
   "source": [
    "Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67eb3c4-552e-4206-96ca-fbbbb4d52f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class GaborConv2d(Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=48, dilation=1,groups=1,bias=False, padding_mode=\"reflect\"): \n",
    "        super().__init__()\n",
    "        self.is_calculated = False\n",
    "\n",
    "        self.conv_layer = Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode)\n",
    "        self.kernel_size = self.conv_layer.kernel_size\n",
    "\n",
    "        # small addition to avoid division by zero\n",
    "        self.delta = 1e-3\n",
    "\n",
    "        #Frequency\n",
    "        self.freq = Parameter(\n",
    "            (math.pi / 2)\n",
    "            * math.sqrt(2)\n",
    "            ** (-torch.randint(0, 5, (out_channels, in_channels))).type(torch.Tensor),\n",
    "            requires_grad=True,\n",
    "        )\n",
    "        #Theta\n",
    "        self.theta = Parameter(\n",
    "            (math.pi / 8)\n",
    "            * torch.randint(0, 8, (out_channels, in_channels)).type(torch.Tensor),\n",
    "            requires_grad=True,\n",
    "        )\n",
    "        #Sigma\n",
    "        self.sigma = Parameter(math.pi / self.freq, requires_grad=True)\n",
    "\n",
    "        #Psi\n",
    "        self.psi = Parameter(\n",
    "            math.pi * torch.rand(out_channels, in_channels), requires_grad=True\n",
    "        )\n",
    "\n",
    "        self.x0 = Parameter(\n",
    "            torch.ceil(torch.Tensor([self.kernel_size[0] / 2]))[0], requires_grad=False\n",
    "        )\n",
    "        self.y0 = Parameter(\n",
    "            torch.ceil(torch.Tensor([self.kernel_size[1] / 2]))[0], requires_grad=False\n",
    "        )\n",
    "\n",
    "        self.y, self.x = torch.meshgrid(\n",
    "            [\n",
    "                torch.linspace(-self.x0 + 1, self.x0 + 0, self.kernel_size[0]),\n",
    "                torch.linspace(-self.y0 + 1, self.y0 + 0, self.kernel_size[1]),\n",
    "            ]\n",
    "        )\n",
    "        self.y = Parameter(self.y.clone())\n",
    "        self.x = Parameter(self.x.clone())\n",
    "\n",
    "        self.weight = Parameter(\n",
    "            torch.empty(self.conv_layer.weight.shape, requires_grad=True),\n",
    "            requires_grad=True,\n",
    "        )\n",
    "\n",
    "        self.register_parameter(\"freq\", self.freq)\n",
    "        self.register_parameter(\"theta\", self.theta)\n",
    "        self.register_parameter(\"sigma\", self.sigma)\n",
    "        self.register_parameter(\"psi\", self.psi)\n",
    "        self.register_parameter(\"x_shape\", self.x0)\n",
    "        self.register_parameter(\"y_shape\", self.y0)\n",
    "        self.register_parameter(\"y_grid\", self.y)\n",
    "        self.register_parameter(\"x_grid\", self.x)\n",
    "        self.register_parameter(\"weight\", self.weight)\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        if self.training:\n",
    "            self.calculate_weights()\n",
    "            self.is_calculated = False\n",
    "        if not self.training:\n",
    "            if not self.is_calculated:\n",
    "                self.calculate_weights()\n",
    "                self.is_calculated = True\n",
    "        return self.conv_layer(input_tensor)\n",
    "\n",
    "    def calculate_weights(self):\n",
    "        for i in range(self.conv_layer.out_channels):\n",
    "            for j in range(self.conv_layer.in_channels):\n",
    "                sigma = self.sigma[i, j].expand_as(self.y) \n",
    "                freq = self.freq[i, j].expand_as(self.y) \n",
    "                theta = self.theta[i, j].expand_as(self.y) \n",
    "                psi = self.psi[i, j].expand_as(self.y) \n",
    "\n",
    "                rotx = self.x * torch.cos(theta) + self.y * torch.sin(theta)\n",
    "                roty = -self.x * torch.sin(theta) + self.y * torch.cos(theta)\n",
    "\n",
    "                g = torch.exp(\n",
    "                    -0.5 * ((rotx ** 2 + roty ** 2) / (sigma + self.delta) ** 2)\n",
    "                )\n",
    "                g = g * torch.cos(freq * rotx + psi)\n",
    "                g = g / (2 * math.pi * sigma ** 2)\n",
    "                self.conv_layer.weight.data[i, j] = g\n",
    "\n",
    "    def _forward_unimplemented(self, *inputs: Any):\n",
    "        \"\"\"\n",
    "        code checkers makes implement this method,\n",
    "        looks like error in PyTorch\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "        \n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = torch.tensor([x2.size()[2] - x1.size()[2]])\n",
    "        diffX = torch.tensor([x2.size()[3] - x1.size()[3]])\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class filt_cat(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x1, x2):     \n",
    "\n",
    "        # input is CHW\n",
    "        diffY = torch.tensor([x2.size()[2] - x1.size()[2]])\n",
    "        diffX = torch.tensor([x2.size()[3] - x1.size()[3]])\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return x;\n",
    "\n",
    "class SNP_Net(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(SNP_Net, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.g0 = GaborConv2d(n_channels, n_channels, kernel_size=(96, 96))\n",
    "        self.fc = filt_cat(n_channels, 2*n_channels)\n",
    "        self.inc = DoubleConv(2*n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 512)\n",
    "        self.up1 = Up(1024, 256, bilinear)\n",
    "        self.up2 = Up(512, 128, bilinear)\n",
    "        self.up3 = Up(256, 64, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        f = self.g0(x)\n",
    "        x0 = self.fc(f,x);\n",
    "        x1 = self.inc(x0)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        x = self.outc(x)\n",
    "        m = nn.Softmax(dim=1)\n",
    "        logits = m(x)\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d952f9-c4b0-4e57-b95c-6a430b5fb4c1",
   "metadata": {},
   "source": [
    "Segmentation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e6d97e-65d0-4fb0-ab5b-e325ef843412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation_metrics(confusion_matrix, per_class=False):\n",
    "    ret = {\n",
    "        'mIoU': confusion_matrix.get_mean_class_iou(),\n",
    "        'mDice': confusion_matrix.get_mean_class_dice(),\n",
    "        'oAcc': confusion_matrix.get_overall_accuracy(),\n",
    "        'mSens': confusion_matrix.get_mean_class_sensitivity(),\n",
    "        'mSpec': confusion_matrix.get_mean_class_specificity(),\n",
    "        'mF1': confusion_matrix.get_mean_class_f1(),\n",
    "    }\n",
    "    if per_class:\n",
    "        for c,v in enumerate(confusion_matrix.get_dice_per_class()):\n",
    "            ret['Dice{}'.format(c)] = v\n",
    "        for c,v in enumerate(confusion_matrix.get_sensitivity_per_class()):\n",
    "            ret['Sens{}'.format(c)] = v\n",
    "        for c,v in enumerate(confusion_matrix.get_specificity_per_class()):\n",
    "            ret['Spec{}'.format(c)] = v\n",
    "        for c,v in enumerate(confusion_matrix.get_f1_per_class()):\n",
    "            ret['F1{}'.format(c)] = v\n",
    "        for c,v in enumerate(confusion_matrix.get_ground_truth_ratios()):\n",
    "            ret['RGt{}'.format(c)] = v\n",
    "        for c,v in enumerate(confusion_matrix.get_prediction_ratios()):\n",
    "            ret['RPr{}'.format(c)] = v\n",
    "    return ret\n",
    "\n",
    "\n",
    "class ConfusionMatrix():\n",
    "    \"\"\"Maintains a running confusion matrix for a K-class classification problem.\n",
    "    Rows corresponds to ground-truth targets and columns corresponds to predicted targets.\"\"\"\n",
    "\n",
    "    def __init__(self, k):\n",
    "        self.cm = np.zeros(shape=(k, k), dtype=object)  # array of python ints for unlimited precision\n",
    "        self.k = k\n",
    "\n",
    "    def reset(self):\n",
    "        self.cm.fill(0)\n",
    "\n",
    "    def add(self, predicted, target):\n",
    "        \"\"\"\n",
    "        Adds new results to the confusion matrix. Filters elements without ground truth (class = -100).\n",
    "\n",
    "        :param predicted: N, BHW or BDHW-sized tensor of class integers or NK, BKHW or BKDHW-sized tensor\n",
    "                          of predicted probabilities\n",
    "        :param target: N, BHW or BDHW-sized tensor of class integers or NK, BKHW or BKDHW-sized tensor\n",
    "                          of one-hot encoded classes\n",
    "        \"\"\"\n",
    "        # TODO: rewrite into pytorch for speed (no need to copy back to device)\n",
    "\n",
    "        if isinstance(predicted, torch.Tensor):\n",
    "            predicted = predicted.detach().cpu().numpy()\n",
    "        if isinstance(target, torch.Tensor):\n",
    "            target = target.detach().cpu().numpy()\n",
    "\n",
    "        if np.ndim(predicted) > 1 and predicted.shape[1] == self.k:\n",
    "            predicted = np.argmax(predicted, 1)\n",
    "        else:\n",
    "            assert (predicted.max() < self.k) and (predicted.min() >= 0), \\\n",
    "                'predicted values are not between 0 and k-1'\n",
    "\n",
    "        if np.ndim(target) > 1 and target.shape[1] == self.k:\n",
    "            assert (target >= 0).all() and (target <= 1).all(), \\\n",
    "                'in one-hot encoding, target values should be 0 or 1'\n",
    "            invalid_idx = target.sum(1) < 0.5\n",
    "            target = np.argmax(target, 1)\n",
    "            target[invalid_idx] = -100\n",
    "\n",
    "        predicted = np.ravel(predicted)\n",
    "        target = np.ravel(target)\n",
    "        assert predicted.shape[0] == target.shape[0], \\\n",
    "            'number of targets and predicted outputs do not match'\n",
    "\n",
    "        # Remove predictions for elements without ground truth\n",
    "        valid_idx = target != -100\n",
    "        target = target[valid_idx]\n",
    "        predicted = predicted[valid_idx]\n",
    "\n",
    "        # from https://github.com/pytorch/tnt/blob/master/torchnet/meter/confusionmeter.py\n",
    "        # (sklearn.metrics.confusion_matrix is 100x slower)\n",
    "\n",
    "        \n",
    "        x = predicted + self.k * target\n",
    " \n",
    "        \n",
    "        bincount_2d = np.bincount(x.astype(np.int64),\n",
    "                                  minlength=self.k ** 2)\n",
    "        \n",
    "        \n",
    "        assert bincount_2d.size == self.k ** 2\n",
    "        cm = bincount_2d.reshape((self.k, self.k))\n",
    "\n",
    "        self.cm += cm\n",
    "\n",
    "    def value(self, normalized=False):\n",
    "        \"\"\"\n",
    "        :return confusion matrix of K rows and K columns\n",
    "        \"\"\"\n",
    "        conf = self.cm.astype(np.float64)\n",
    "        if normalized:\n",
    "            return conf / conf.sum(1).clip(min=1e-12)[:, None]\n",
    "        else:\n",
    "            return conf\n",
    "\n",
    "    def get_iou_per_class(self):\n",
    "        \"\"\"\n",
    "        :return per-class intersection-over-union / Jaccard coefficient (NaN if class not present nor predicted)\n",
    "        \"\"\"\n",
    "        cm = self.value()\n",
    "        tp = np.diag(cm)\n",
    "        rowsum = cm.sum(axis=0)\n",
    "        colsum = cm.sum(axis=1)\n",
    "        with np.errstate(invalid='ignore'):\n",
    "            return tp / (rowsum + colsum - tp)\n",
    "\n",
    "    def get_mean_class_iou(self):\n",
    "        \"\"\"\n",
    "        :return mean per-class intersection-over-union / Jaccard coefficient (over classes present)\n",
    "        \"\"\"\n",
    "        iou = self.get_iou_per_class()\n",
    "        iou = iou[~np.isnan(iou)]\n",
    "        return np.mean(iou)\n",
    "\n",
    "    def get_overall_accuracy(self):\n",
    "        \"\"\"\n",
    "        :return overall sensitivity (class-unspecific)\n",
    "        \"\"\"\n",
    "        cm = self.value()\n",
    "        tp = np.diag(cm).sum()\n",
    "        oa = tp / max(1, np.sum(cm))\n",
    "        return oa\n",
    "\n",
    "    def get_sensitivity_per_class(self):\n",
    "        \"\"\"\n",
    "        :return per-class sensitivity (NaN if class not present)\n",
    "        \"\"\"\n",
    "        cm = self.value()\n",
    "        tp = np.diag(cm)\n",
    "        with np.errstate(invalid='ignore'):\n",
    "            return tp / np.sum(cm, axis=1)\n",
    "\n",
    "    def get_mean_class_sensitivity(self):\n",
    "        \"\"\"\n",
    "        :return mean per-class sensitivity (over classes present)\n",
    "        \"\"\"\n",
    "        sens = self.get_sensitivity_per_class()\n",
    "        sens = sens[~np.isnan(sens)]\n",
    "        return np.mean(sens)\n",
    "\n",
    "\n",
    "    def get_specificity_per_class(self):\n",
    "        \"\"\"\n",
    "        :return per-class specificity (NaN if class not present)\n",
    "        \"\"\"\n",
    "        cm = copy.deepcopy(self.value())\n",
    "        tp = np.diag(copy.deepcopy(cm))\n",
    "        tn = copy.deepcopy(tp);\n",
    "        for i in range(0,len(tn)):\n",
    "          tn[i] = tp.sum() - tp[i];\n",
    "          cm[i,i] = 0;\n",
    "\n",
    "        with np.errstate(invalid='ignore'):\n",
    "            return tn /(tn +  np.sum(cm, axis=0))\n",
    "\n",
    "    def get_mean_class_specificity(self):\n",
    "        \"\"\"\n",
    "        :return mean per-class specificity (over classes present)\n",
    "        \"\"\"\n",
    "        spec = self.get_specificity_per_class()\n",
    "        spec = spec[~np.isnan(spec)]\n",
    "        return np.mean(spec)\n",
    "\n",
    "    def get_f1_per_class(self):\n",
    "        \"\"\"\n",
    "        :return per-class f1 (NaN if class not present)\n",
    "        \"\"\"\n",
    "        cm = self.value()\n",
    "        tp = np.diag(cm)\n",
    "        with np.errstate(invalid='ignore'):\n",
    "            return tp / (0.5*(np.sum(cm, axis=1) + np.sum(cm, axis=0)))\n",
    "\n",
    "\n",
    "    def get_mean_class_f1(self):\n",
    "        \"\"\"\n",
    "        :return mean per-class f1 (over classes present)\n",
    "        \"\"\"\n",
    "        f1 = self.get_f1_per_class()\n",
    "        f1 = f1[~np.isnan(f1)]\n",
    "        return np.mean(f1)\n",
    "\n",
    "\n",
    "\n",
    "    def get_dice_per_class(self):\n",
    "        \"\"\"\n",
    "        :return per-class Dice coefficient (NaN if class not present nor predicted)\n",
    "        \"\"\"\n",
    "        with np.errstate(invalid='ignore'):\n",
    "            jacc = self.get_iou_per_class()\n",
    "            return 2 * jacc / (jacc + 1)\n",
    "\n",
    "    def get_mean_class_dice(self):\n",
    "        \"\"\"\n",
    "        :return mean per-class Dice coefficient (over classes present)\n",
    "        \"\"\"\n",
    "        dice = self.get_dice_per_class()\n",
    "        dice = dice[~np.isnan(dice)]\n",
    "        return np.mean(dice)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a455b54c-388b-414d-9022-d9d1ff4859fe",
   "metadata": {},
   "source": [
    "Find Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302e15d3-5313-49e6-a7f3-3861a170ba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_edges(color_mask):\n",
    "    \n",
    "\n",
    "    #Dimensions\n",
    "    [rows, cols] = color_mask.shape\n",
    "\n",
    "    struct1 = ndimage.generate_binary_structure(2, 2)\n",
    "\n",
    "    all_edges = np.zeros([rows, cols]);\n",
    "    for color_idx in range(0,4):\n",
    "\n",
    "        #Binary Mask\n",
    "        mask = copy.deepcopy(color_mask);\n",
    "        mask[np.where(color_mask==color_idx)] = 1;\n",
    "        mask[np.where(color_mask!=color_idx)] = 0;\n",
    "\n",
    "        #Empty Positions\n",
    "        up = np.zeros([rows, cols])\n",
    "        down = np.zeros([rows, cols])\n",
    "        left = np.zeros([rows, cols])\n",
    "        right = np.zeros([rows, cols])\n",
    "        up_left = np.zeros([rows, cols])\n",
    "        up_right = np.zeros([rows, cols])\n",
    "        down_left = np.zeros([rows, cols])\n",
    "        down_right = np.zeros([rows, cols])\n",
    "\n",
    "        #Shift Positions\n",
    "        up[:rows-1, :] = mask[1:rows,:]\n",
    "        down[1:rows,:] = mask[0:rows-1,:]\n",
    "        left[:,:cols-1] = mask[:,1:cols]\n",
    "        right[:,1:cols] = mask[:,:cols-1]\n",
    "        up_left[0:rows-1,0:cols-1] = mask[1:rows,1:cols]\n",
    "        up_right[0:rows-1,1:cols] = mask[1:rows,0:cols-1]\n",
    "        down_left[1:rows,0:cols-1] = mask[0:rows-1,1:cols]\n",
    "        down_right[1:rows,1:cols] = mask[0:rows-1,0:cols-1]\n",
    "\n",
    "        #Fill if Coincides with the Center\n",
    "        conn = np.zeros([8,rows, cols])\n",
    "        conn[0] = mask*down_right\n",
    "        conn[1] = mask*down\n",
    "        conn[2] = mask*down_left\n",
    "        conn[3] = mask*right\n",
    "        conn[4] = mask*left\n",
    "        conn[5] = mask*up_right\n",
    "        conn[6] = mask*up\n",
    "        conn[7] = mask*up_left\n",
    "        \n",
    "\n",
    "        #Find Edges & Non-Edges\n",
    "        sum_conn = np.sum(conn,axis=0)\n",
    "        not_full = np.where(sum_conn<8,np.full_like(sum_conn, 1),np.full_like(sum_conn, 0))\n",
    "        salient = np.where(sum_conn>0,np.full_like(sum_conn, 1),np.full_like(sum_conn, 0))\n",
    "        edge = not_full*salient;\n",
    "   \n",
    "        if(color_idx==1):\n",
    "            all_edges = edge;\n",
    "\n",
    "        else:\n",
    "            all_edges +=edge;\n",
    "\n",
    "\n",
    "    #Remove Overlap\n",
    "    all_edges[np.where(all_edges>1)] = 1;\n",
    "    all_edges = ndimage.binary_dilation(all_edges, structure=struct1).astype(all_edges.dtype)\n",
    "\n",
    "\n",
    "\n",
    "    return all_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e304b0-f005-4059-bd09-ffad2cc5e176",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7770f6-1dc3-4c98-a222-bf4d7fb55015",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicDataset(Dataset):\n",
    "    \n",
    "    \n",
    "    def __init__(self, images, masks, masks_AAR, images_compression, masks_compression, Train):\n",
    "        \n",
    "\n",
    "        #Attributes\n",
    "        self.images = images;\n",
    "        self.masks = masks;\n",
    "        self.masks_AAR = masks_AAR;\n",
    "        self.images_compression = images_compression;\n",
    "        self.masks_compression = masks_compression;\n",
    "        self.Train = Train;\n",
    "        self.Positions = np.array([[0,0], [0,96], [0,192], [0,288], [96,0], [96,96], [96,192], [96,288], [192,0], [192,96], [192,192], [192,288], [288,0], [288,96], [288,192], [288,288]])\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        #Length\n",
    "        return np.shape(self.images)[0]\n",
    "\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "\n",
    "\n",
    "        #Extract Images and Masks\n",
    "        img = self.images[i,:,:].squeeze().copy();\n",
    "        mask = self.masks[i,:,:].squeeze().copy();\n",
    "        mask_AAR = self.masks_AAR[i,:,:].squeeze().copy();\n",
    "        \n",
    "        #Rows and Columns\n",
    "        indices = np.arange(0,16)\n",
    "        np.random.shuffle(indices);\n",
    "        row_shift = randint(-48,48);\n",
    "        col_shift = randint(-48,48);\n",
    "\n",
    "        #Normalize\n",
    "        img = img/np.max(img);\n",
    "        img = img - 0.5;\n",
    "        \n",
    "        #Iterate   \n",
    "        for g_index in range(0,16):\n",
    "\n",
    "            #Select Window\n",
    "            d_row = 96;\n",
    "            d_col = 96;\n",
    "            idx = indices[g_index];\n",
    "            row = self.Positions[idx,0] + row_shift;\n",
    "            col = self.Positions[idx,1] + col_shift;\n",
    "            if(row<0):\n",
    "                row = 0;\n",
    "            if(col<0):\n",
    "                col = 0;\n",
    "            if(row>288):\n",
    "                row = 288;\n",
    "            if(col>288):\n",
    "                col = 288;            \n",
    "            \n",
    "\n",
    "            #Crop \n",
    "            cropped_img = img[row:row+d_row,col:col+d_col].copy();           \n",
    "            cropped_mask = mask[row:row+d_row,col:col+d_col].copy();                  \n",
    "            cropped_mask_AAR = mask_AAR[row:row+d_row,col:col+d_col].copy();\n",
    "\n",
    "            \n",
    "            #Add Compression Artifact\n",
    "            if(self.Train==1 and randint(0,1) ==0):\n",
    "\n",
    "                #Select Compression Image\n",
    "                c_idx = randint(0, np.shape(self.images_compression)[0]-1);\n",
    "                img_compression = self.images_compression[c_idx,:,:].squeeze().copy();\n",
    "                mask_compression = self.masks_compression[c_idx,:,:].squeeze().copy();              \n",
    "                     \n",
    "                    \n",
    "                #Normalize\n",
    "                img_compression = img_compression/np.max(img_compression);\n",
    "                img_compression = img_compression - 0.5;\n",
    "                \n",
    "                #Select Window\n",
    "                row = randint(0,288);\n",
    "                col = randint(0,288);              \n",
    "                d_row = 96;\n",
    "                d_col = 96;\n",
    "                \n",
    "                \n",
    "                #Crop \n",
    "                cropped_img_compression = img_compression[row:row+d_row,col:col+d_col].copy();\n",
    "                cropped_mask_compression = mask_compression[row:row+d_row,col:col+d_col].copy();  \n",
    "                \n",
    "\n",
    "                \n",
    "                #Filter\n",
    "                sigma_var = 5;\n",
    "                filter_smooth = ndimage.gaussian_filter(cropped_mask_compression, sigma=(sigma_var, sigma_var), order=0)\n",
    "                filter_smooth_opp = 1 - filter_smooth;\n",
    "                filter_binary = np.round(filter_smooth);\n",
    "\n",
    "\n",
    "                #Apply Filters\n",
    "                cropped_img = (cropped_img * filter_smooth_opp) + (cropped_img_compression * filter_smooth);\n",
    "                mask[np.where(filter_binary==1)] = 0;\n",
    "\n",
    "                #Find Edges\n",
    "                edge = find_edges(cropped_mask);\n",
    "                edge[np.where(filter_binary==1)] = 0;\n",
    "\n",
    "\n",
    "            else:\n",
    "                #Find Edges\n",
    "                edge = find_edges(cropped_mask);           \n",
    "            \n",
    "            \n",
    "               \n",
    "            #Expand Dim\n",
    "            cropped_img = np.expand_dims(cropped_img,axis = 0);\n",
    "            cropped_mask = np.expand_dims(cropped_mask,axis = 0);\n",
    "            cropped_mask_AAR = np.expand_dims(cropped_mask_AAR,axis = 0);\n",
    "            edge = np.expand_dims(edge,axis = 0);\n",
    "\n",
    "            #Add to Group\n",
    "            if(g_index ==0):\n",
    "                images = cropped_img;\n",
    "                masks = cropped_mask;\n",
    "                masks_AAR = cropped_mask_AAR;\n",
    "                edges = edge;   \n",
    "            else:\n",
    "                images = np.concatenate((images, cropped_img), 0);\n",
    "                masks = np.concatenate((masks, cropped_mask), 0);\n",
    "                masks_AAR = np.concatenate((masks_AAR, cropped_mask_AAR), 0);\n",
    "                edges = np.concatenate((edges, edge), 0);\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        return {'images': images, 'masks': masks,'masks_AAR': masks_AAR, 'edges': edges}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1516ebac-f880-45f4-8951-81b84653fb53",
   "metadata": {},
   "source": [
    "Evaluate Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9f6b62-b9d2-4c03-8075-71bc972b9c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_net(net, loader, tissues, device, n_val, batch_size):\n",
    "    \n",
    "    #Evaluation Mode\n",
    "    net.eval();\n",
    "    \n",
    "    #Initialize\n",
    "    val_dice = [];\n",
    "    val_dice_0 = [];\n",
    "    val_dice_1 = [];\n",
    "    val_dice_2 = [];\n",
    "    val_dice_3 = [];\n",
    "    val = np.zeros((tissues+1))\n",
    "\n",
    "    #Display Progress Bar\n",
    "    with tqdm(total=n_val, desc='Validation round', unit='img', leave=False) as pbar:\n",
    "        \n",
    "        #Iterate\n",
    "        for batch in loader:\n",
    "          \n",
    "            #Load\n",
    "            imgs = torch.from_numpy(np.reshape(np.array(batch['images']), (-1,1,96,96))).to(device=device, dtype=torch.float32);\n",
    "            targets = torch.from_numpy(np.reshape(np.array(batch['masks']), (-1,1,96,96))).to(device=device, dtype=torch.long);\n",
    "            targets_AAR = torch.from_numpy(np.reshape(np.array(batch['masks_AAR']), (-1,1,96,96))).to(device=device, dtype=torch.long);\n",
    "\n",
    "\n",
    "            #Predict\n",
    "            predictions = net(imgs);\n",
    "\n",
    "            #Applanation Artifact Removal\n",
    "            targets = targets*targets_AAR;\n",
    "\n",
    "                \n",
    "            #DSC Calculation\n",
    "            cm = ConfusionMatrix(tissues)\n",
    "            cm.add(predictions, targets.squeeze(1))\n",
    "            acc_out = segmentation_metrics(cm);\n",
    "            dice_per_class = cm.get_f1_per_class();\n",
    "            val_dice.append(acc_out['mF1']);\n",
    "            val_dice_0.append(dice_per_class[0]);\n",
    "            val_dice_1.append(dice_per_class[1]);\n",
    "            val_dice_2.append(dice_per_class[2]);\n",
    "            val_dice_3.append(dice_per_class[3]);\n",
    "                        \n",
    "            #Update Progress Bar\n",
    "            pbar.update(batch_size);\n",
    "\n",
    "            \n",
    "    #Average Dice\n",
    "    val[0] = np.nanmean(np.array(val_dice));\n",
    "    val[1] = np.nanmean(np.array(val_dice_0));\n",
    "    val[2] = np.nanmean(np.array(val_dice_1));\n",
    "    val[3] = np.nanmean(np.array(val_dice_2));\n",
    "    val[4] = np.nanmean(np.array(val_dice_3));\n",
    "\n",
    "\n",
    "    return val;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edfdebf-2b8a-489c-aade-98d7133b4ee0",
   "metadata": {},
   "source": [
    "Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe6667a-76c1-4aec-8e9b-2b3d40c91670",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_net(net, epochs, tissues, lr, batch_size, t ,g, python_path, torch_path, Experiment_Name, Model_Name):\n",
    "\n",
    "  \n",
    "\n",
    "    #Load Numpy Files\n",
    "    PID =  np.load(python_path + 'SNP_Net_Groups.npy');   \n",
    "    images = np.load(python_path + 'SNP_Net_Images.npy');\n",
    "    masks = np.load(python_path + 'SNP_Net_Masks.npy');\n",
    "    masks_AAR = np.load(python_path  + 'AAR_Net_Masks.npy');                 \n",
    "    images_compression = np.load(python_path + 'SNP_Net_Images_Compression.npy');             \n",
    "    masks_compression = np.load(python_path + 'SNP_Net_Masks_Compression.npy'); \n",
    "  \n",
    "\n",
    "    #Correct Applanation Artifact Removal\n",
    "    masks_AAR = (masks_AAR==0);\n",
    "    masks_AAR = masks_AAR *1.0;\n",
    "\n",
    "    #Split into Training & Validation Set\n",
    "    indices = np.arange(0,np.shape(images)[0]);\n",
    "    val_idx = t + 1;\n",
    "    if(val_idx >20):\n",
    "      val_idx = 0;\n",
    "    indices_train = indices[np.where((PID!= t) & (PID!= val_idx))]\n",
    "    indices_val = indices[np.where(PID== val_idx)]    \n",
    "    \n",
    " \n",
    "    #Shuffle Data\n",
    "    np.random.shuffle(indices_train);\n",
    "    images_train = images[indices_train];\n",
    "    masks_train = masks[indices_train];\n",
    "    masks_AAR_train = masks_AAR[indices_train];\n",
    "    np.random.shuffle(indices_val);\n",
    "    images_val = images[indices_val];\n",
    "    masks_val = masks[indices_val];\n",
    "    masks_AAR_val = masks_AAR[indices_val];\n",
    "\n",
    "\n",
    "    #Construct Datasets\n",
    "    train_dataset = BasicDataset(images_train, masks_train, masks_AAR_train, images_compression, masks_compression, 1);\n",
    "    val_dataset = BasicDataset(images_val, masks_val, masks_AAR_val, images_compression, masks_compression, 0); \n",
    "    \n",
    "    #Construct Loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True);\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=16, pin_memory=True);\n",
    "\n",
    "\n",
    "    #Write the Training Parameters to the Log File\n",
    "    logging.info(f'''Started training:\n",
    "        Epochs:          {epochs}\n",
    "        Batch size:      {batch_size}\n",
    "        Learning rate:   {lr}\n",
    "        Training size:   {len(train_dataset)}\n",
    "        Validation size: {len(val_dataset)}\n",
    "        Device:          {device.type}\n",
    "    ''');\n",
    "\n",
    "\n",
    "    #Optimizer and Scheduler\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=1e-8);\n",
    "    scheduler = StepLR(optimizer, step_size = 20, gamma = 0.5)\n",
    "  \n",
    "\n",
    "    #Results\n",
    "    training = np.zeros((tissues+1,epochs));\n",
    "    validation = np.zeros((tissues+1,epochs));\n",
    "\n",
    "\n",
    "    #Iterate through Epochs\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        #Begin Training\n",
    "        net.train();\n",
    "\n",
    "\n",
    "        #Initialize Epoch Loss\n",
    "        epoch_loss = 0;\n",
    "        \n",
    "        #Initialize \n",
    "        train_dice = [];\n",
    "        train_dice_0 = [];\n",
    "        train_dice_1 = [];\n",
    "        train_dice_2 = [];\n",
    "        train_dice_3 = [];\n",
    "\n",
    "        #Display Progress Bar\n",
    "        with tqdm(total=len(train_dataset), desc=f'Epoch {epoch + 1}/{epochs}', unit='img') as pbar:\n",
    "            \n",
    "            \n",
    "            #Iterate\n",
    "            for batch in train_loader:\n",
    "                \n",
    "                # ---------------------\n",
    "                #  Use Network\n",
    "                # ---------------------\n",
    "                \n",
    "                \n",
    "                #Load\n",
    "                imgs = torch.from_numpy(np.reshape(np.array(batch['images']), (-1,1,96,96))).to(device=device, dtype=torch.float32);\n",
    "                targets = torch.from_numpy(np.reshape(np.array(batch['masks']), (-1,1,96,96))).to(device=device, dtype=torch.long);\n",
    "                targets_AAR = torch.from_numpy(np.reshape(np.array(batch['masks_AAR']), (-1,1,96,96))).to(device=device, dtype=torch.long);\n",
    "                edges = torch.from_numpy(np.reshape(np.array(batch['edges']), (-1,1,96,96))).to(device=device, dtype=torch.float32);\n",
    "\n",
    "\n",
    "                #Predict\n",
    "                predictions = net(imgs);\n",
    "\n",
    "\n",
    "                #Applanation Artifact Removal\n",
    "                targets = targets*targets_AAR;\n",
    "      \n",
    "     \n",
    "                # ---------------------\n",
    "                #  Train Encoder-Decoder \n",
    "                # ---------------------\n",
    "\n",
    "                \n",
    "                #Ratio\n",
    "                total_size = np.size(targets.cpu().numpy());\n",
    "                class_0 = np.where(targets.cpu().numpy()==0);            \n",
    "                class_1 = np.where(targets.cpu().numpy()==1);                \n",
    "                class_2 = np.where(targets.cpu().numpy()==2);                \n",
    "                class_3 = np.where(targets.cpu().numpy()==3);  \n",
    "                if(len(class_0[0]) !=0):\n",
    "                    ratio_0 = total_size/len(class_0[0]);    \n",
    "                else:\n",
    "                    ratio_0 = 0;                  \n",
    "                if(len(class_1[0]) !=0):\n",
    "                    ratio_1 = total_size/len(class_1[0]);    \n",
    "                else:\n",
    "                    ratio_1 = 0;               \n",
    "                if(len(class_2[0]) !=0):\n",
    "                    ratio_2 = total_size/len(class_2[0]);    \n",
    "                else:\n",
    "                    ratio_2 = 0;                              \n",
    "                if(len(class_3[0]) !=0):\n",
    "                    ratio_3 = total_size/len(class_3[0]);    \n",
    "                else:\n",
    "                    ratio_3 = 0;       \n",
    "                \n",
    "                #Inverse Class Weights\n",
    "                weights = [np.power(ratio_0,1/5), np.power(ratio_1, 1/5), np.power(ratio_2,1/5), np.power(ratio_3,1/5)];\n",
    "                class_weights = torch.FloatTensor(weights).cuda();    \n",
    "           \n",
    "                \n",
    "                #Loss Function\n",
    "                cross_entropy = nn.CrossEntropyLoss(weight = class_weights, reduction = 'none');\n",
    "                loss_matrix = cross_entropy(predictions, targets.squeeze(1)); \n",
    "                loss_matrix = loss_matrix*targets_AAR.squeeze(1);\n",
    "\n",
    "                #Inverse-Class and Edge Loss\n",
    "                inverse_loss = torch.mean(loss_matrix);\n",
    "                edge_loss = torch.mean(loss_matrix*edges)\n",
    "\n",
    "                #Overall Loss  \n",
    "                loss =  (inverse_loss + 3*edge_loss )/3.0;   \n",
    "                \n",
    "\n",
    "                #Back Propagation: Discriminator\n",
    "                optimizer.zero_grad();\n",
    "                loss.backward();\n",
    "                optimizer.step();\n",
    "\n",
    " \n",
    "\n",
    "                # ---------------------\n",
    "                #  Metrics\n",
    "                # ---------------------\n",
    "\n",
    "            \n",
    "                #DSC Calculation\n",
    "                cm = ConfusionMatrix(tissues)\n",
    "                cm.add(predictions, targets.squeeze(1))\n",
    "                acc_out = segmentation_metrics(cm);\n",
    "                dice_per_class = cm.get_f1_per_class();\n",
    "                train_dice.append(acc_out['mF1']);\n",
    "                train_dice_0.append(dice_per_class[0]);\n",
    "                train_dice_1.append(dice_per_class[1]);\n",
    "                train_dice_2.append(dice_per_class[2]);\n",
    "                train_dice_3.append(dice_per_class[3]);\n",
    "\n",
    "                #Update \n",
    "                pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
    "\n",
    "                #Update Progress Bar\n",
    "                pbar.update(batch_size)\n",
    "\n",
    "\n",
    "        #Average Training Dice\n",
    "        training[0,epoch] = np.nanmean(np.array(train_dice));\n",
    "        training[1,epoch] = np.nanmean(np.array(train_dice_0));\n",
    "        training[2,epoch] = np.nanmean(np.array(train_dice_1));\n",
    "        training[3,epoch] = np.nanmean(np.array(train_dice_2));\n",
    "        training[4,epoch] = np.nanmean(np.array(train_dice_3));\n",
    "\n",
    "        #Average Validation Dice\n",
    "        validation[:,epoch] = eval_net(net, val_loader, tissues, device, len(train_dataset), batch_size);\n",
    "\n",
    "        \n",
    "        #Print Results\n",
    "        logging.info('Average Train Dice: ' + str(training[0,epoch]))\n",
    "        logging.info('Average Train Dice Background: ' + str(training[1,epoch]))  \n",
    "        logging.info('Average Train Dice Nerve: ' + str(training[2,epoch]))  \n",
    "        logging.info('Average Train Dice Neuroma: ' + str(training[4,epoch]))  \n",
    "        logging.info('Average Train Dice Immune: ' + str(training[3,epoch]))  \n",
    "        \n",
    "        logging.info('Average Val Dice: ' + str(validation[0,epoch]))   \n",
    "        logging.info('Average Val Dice Background: ' + str(validation[1,epoch]))  \n",
    "        logging.info('Average Val Dice Nerve: ' + str(validation[2,epoch]))  \n",
    "        logging.info('Average Val Dice Neuroma: ' + str(validation[4,epoch])) \n",
    "        logging.info('Average Val Dice Immune: ' + str(validation[3,epoch]))  \n",
    "\n",
    "\n",
    "        #Learning Rate Scheduler\n",
    "        scheduler.step()            \n",
    "            \n",
    "        #Save Model\n",
    "        torch.save(net.state_dict(), torch_path + Model_Name + '_' + Experiment_Name + '_Group_' + str(t) +'_' + str(g) + '_Epoch_' +str(epoch+1) +'.pth')\n",
    "        \n",
    "        #Save Training Metrics\n",
    "        np.save(torch_path  +'Training_Dice_'+ Model_Name + '_' + Experiment_Name + '_Group_' + str(t) +'_' + str(g) + '_Epoch_' +str(epoch+1) +'.npy', training);\n",
    "        np.save(torch_path  +'Validation_Dice_'+ Model_Name + '_' + Experiment_Name + '_Group_' + str(t) +'_' + str(g) + '_Epoch_' +str(epoch+1) +'.npy', validation);\n",
    " \n",
    "\n",
    "\n",
    "    return training, validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba77c0b-57f6-4a32-b073-52f4751e6a9e",
   "metadata": {},
   "source": [
    "Initialize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2be7b44-0efb-4dec-8a84-0d10ac9795f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cast to Cuda\n",
    "CUDA_VISIBLE_DEVICES=0\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "if cuda:\n",
    "    FloatTensor = torch.cuda.FloatTensor\n",
    "    LongTensor = torch.cuda.LongTensor\n",
    "else:\n",
    "    FloatTensor = torch.FloatTensor\n",
    "    LongTensor = torch.LongTensor\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu');\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b93594-f4e0-4ad3-842f-a0fbeba28339",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c645a42-a800-4f5f-90b0-af2458bde361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "Experiment_Name = 'Original';\n",
    "Model_Name = 'SNP_Net';\n",
    "\n",
    "\n",
    "#Hyper Parameters\n",
    "epochs = 100;\n",
    "lr = 0.0005; \n",
    "batch_size = 5;\n",
    "tissues = 4; \n",
    "channels = 1;\n",
    "\n",
    "#Path\n",
    "python_path = r'/hpc/group/viplab/zzz3/SNP_Segmentation/Files/Python/SNP-Net/';\n",
    "torch_path = r'/hpc/group/viplab/zzz3/SNP_Segmentation/Files/Torch/SNP-Net/';\n",
    "\n",
    "\n",
    "#Set up Basic Configuration of the Log File\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s');\n",
    "logging.info(f'Using device {device}');\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    if(cuda): \n",
    "\n",
    "        for t in range(0,21):\n",
    "\n",
    "            for g in range(0,5):\n",
    "                \n",
    "                #Load Network \n",
    "                net = SNP_Net(n_channels=channels, n_classes=tissues); \n",
    "                net.to(device=device)\n",
    "\n",
    "                #Train\n",
    "                training, validation  =  train_net(net, epochs, tissues, lr, batch_size, t ,g, python_path, torch_path, Experiment_Name, Model_Name);\n",
    "\n",
    "\n",
    "                #Save Training Metrics\n",
    "                np.save(torch_path  +'Training_Dice_'+ Model_Name +'_' + Experiment_Name +'_Group_' + str(t) +'_' + str(g) + '.npy', training);\n",
    "                np.save(torch_path  +'Validation_Dice_'+  Model_Name +'_' + Experiment_Name +'_Group_' + str(t) +'_' + str(g) + '.npy', validation);\n",
    "\n",
    "\n",
    "                epoch = np.argmax(validation[0,60:]) + 60; \n",
    "\n",
    "\n",
    "                #Delete Other Models\n",
    "                for i in range(1,epochs+1):\n",
    "                    if(i !=epoch+1):\n",
    "                        if(os.path.exists(torch_path + Model_Name + '_' + Experiment_Name + '_Group_' + str(t) +'_' + str(g) + '_Epoch_' +str(i) +'.pth')):\n",
    "                                os.remove(torch_path + Model_Name + '_' + Experiment_Name + '_Group_' + str(t) +'_' + str(g) + '_Epoch_' +str(i) +'.pth');\n",
    "\n",
    "                    if(os.path.exists(torch_path  +'Training_Dice_'+ Model_Name + '_' + Experiment_Name + '_Group_' + str(t) +'_' + str(g) + '_Epoch_' +str(i) +'.npy')):\n",
    "                        os.remove(torch_path  +'Training_Dice_'+ Model_Name + '_' + Experiment_Name + '_Group_' + str(t) +'_' + str(g) + '_Epoch_' +str(i) +'.npy');\n",
    "                        os.remove(torch_path  +'Validation_Dice_'+ Model_Name + '_' + Experiment_Name + '_Group_' + str(t) +'_' + str(g) + '_Epoch_' +str(i) +'.npy');\n",
    "\n",
    "\n",
    "except KeyboardInterrupt:\n",
    " \n",
    "    pass  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6848e508-7ca8-4936-8572-f49c45f602bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
