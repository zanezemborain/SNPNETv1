{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cEzPXq-O4YRd"
   },
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rdAyOm4Z4h9A"
   },
   "outputs": [],
   "source": [
    "#Import\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from random import randint\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import random;\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jTRTaia9IMRD"
   },
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SHH8eicnIKHe"
   },
   "outputs": [],
   "source": [
    "class BasicDataset(Dataset):\n",
    "    \n",
    "    \n",
    "    def __init__(self, ccm_images, ccm_labels):\n",
    "        \n",
    "\n",
    "\n",
    "        #Image Attributes\n",
    "        self.ccm_images = ccm_images;\n",
    "        self.ccm_labels = ccm_labels;\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return np.shape(self.ccm_images)[0]\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        \n",
    "        #Obtain Image File \n",
    "        img = self.ccm_images[i,:,:].squeeze().copy();\n",
    "        ccm_label = self.ccm_labels[i,0]\n",
    "        ccm_label = np.expand_dims(ccm_label,axis = 0);\n",
    "\n",
    "        #Multiple Samples       \n",
    "        for group in range(0,4):\n",
    "\n",
    "\n",
    "            #Select Window\n",
    "            if(self.ccm_labels[i,0]==1):\n",
    "             \n",
    "              row = randint(48,143);\n",
    "              col = randint(48,143);\n",
    "\n",
    "            else:      \n",
    "              row = randint(0,191);\n",
    "              col = randint(0,191);\n",
    "                \n",
    "            \n",
    "            #Extract\n",
    "            cropped_img = img[row:row+192,col:col+192].copy();\n",
    "            \n",
    "\n",
    "            #Normalize\n",
    "            cropped_img = (cropped_img - np.min(cropped_img))/(np.max(cropped_img) - np.min(cropped_img))\n",
    "            \n",
    "            #Flip the Image (Horizontal)\n",
    "            if(randint(0,1) ==1):\n",
    "                cropped_img = np.fliplr(cropped_img).copy();\n",
    "\n",
    "        \n",
    "            #Flip the Image (Vertical)\n",
    "            if(randint(0,1) ==1):\n",
    "                cropped_img = np.flipud(cropped_img).copy();\n",
    "\n",
    "            #Expand Dim\n",
    "            cropped_img = np.expand_dims(cropped_img,axis = 0);\n",
    "\n",
    "\n",
    "            if(group ==0):\n",
    "                images = cropped_img;\n",
    "                labels = ccm_label;\n",
    "            else:\n",
    "                #Add to Group\n",
    "                images = np.concatenate((images, cropped_img), 0);\n",
    "                labels = np.concatenate((labels, ccm_label), 0);\n",
    "\n",
    "\n",
    "        return {'ccm_images': images, 'ccm_labels': labels}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7b4V5d5B2Vd"
   },
   "source": [
    "Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gmka7N2bYqcn"
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\"\n",
    "\n",
    "def sample_image(n_row, epochs):\n",
    "    \n",
    "    # Get Sample Noise\n",
    "    z = Variable(FloatTensor(np.random.normal(0, 1, (n_row ** 2, latent_dim))))\n",
    "\n",
    "    # Get Labels\n",
    "    labels = np.array([num for _ in range(n_row) for num in range(n_row)])\n",
    "    labels = Variable(LongTensor(labels))\n",
    "\n",
    "\n",
    "    #Generate Images from Sample Noise and Labels\n",
    "    gen_imgs = generator(z, labels)\n",
    "\n",
    "    x = gen_imgs.data;\n",
    "\n",
    "\n",
    "    #Save Images\n",
    "    save_image(gen_imgs.data, r'/hpc/group/viplab/zzz3/SNP_Segmentation/Files/Images/GAN/%d.png' % epochs, nrow=n_row, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIYwov7eh-Fc"
   },
   "source": [
    "Initialize Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sQnKWo6jiDWz"
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"Initializes weights in networks\"\"\"\n",
    "\n",
    "def weights_init_normal(m):\n",
    "\n",
    "    #Get Class Name\n",
    "    classname = m.__class__.__name__\n",
    "\n",
    "    #Initialize by Layer Type\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nL6fyRInifdf"
   },
   "source": [
    "Generator and Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uiSUTYFviiVP"
   },
   "outputs": [],
   "source": [
    "\n",
    "#######################################################\n",
    "# Generator Network\n",
    "#######################################################\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        #Embeddings Layers\n",
    "        self.label_emb = nn.Embedding(n_classes, latent_dim)\n",
    "\n",
    "        # Initial size before upsampling\n",
    "        self.init_size = img_size // 4  \n",
    "\n",
    "        #Resize\n",
    "        self.l1 = nn.Sequential(nn.Linear(latent_dim, 128 * self.init_size ** 2))\n",
    "\n",
    "        #Convolution Blocks\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, channels, 3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "\n",
    "        #Multiply Noise by Labels\n",
    "        gen_input = torch.mul(self.label_emb(labels), noise)\n",
    "\n",
    "        #Resize\n",
    "        out = self.l1(gen_input)\n",
    "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
    "\n",
    "        #Convolution Blocks\n",
    "        img = self.conv_blocks(out)\n",
    "\n",
    "        #Output\n",
    "        return img;\n",
    "    \n",
    "    \n",
    "#######################################################\n",
    "# Discriminator Network\n",
    "#######################################################\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "\n",
    "        #Discrimator Blocks\n",
    "        def discriminator_block(in_filters, out_filters, bn=True):\n",
    "            \n",
    "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "            return block\n",
    "\n",
    "\n",
    "\n",
    "        #Convolution Blocks\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            *discriminator_block(channels, 16, bn=False),\n",
    "            *discriminator_block(16, 32),\n",
    "            *discriminator_block(32, 64),\n",
    "            *discriminator_block(64, 128),\n",
    "        )\n",
    "\n",
    "        # The height and width of downsampled image\n",
    "        ds_size = img_size // 2 ** 4\n",
    "\n",
    "        # Output layers\n",
    "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())\n",
    "        self.aux_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, n_classes), nn.Softmax())\n",
    "\n",
    "    def forward(self, img):\n",
    "\n",
    "\n",
    "        #Discrimination Convolution Blocks\n",
    "        out = self.conv_blocks(img)\n",
    "\n",
    "        #Reshape\n",
    "        out = out.view(out.shape[0], -1)\n",
    "\n",
    "        #Output Layers\n",
    "        validity = self.adv_layer(out)\n",
    "        label = self.aux_layer(out)\n",
    "\n",
    "\n",
    "        #Output\n",
    "        return validity, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rqnMa4F3KJqL"
   },
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fF0iO5s-Fsxz",
    "outputId": "5a803f54-6138-4daf-d045-55889d6b3fc4"
   },
   "outputs": [],
   "source": [
    "#Path\n",
    "python_path = r'/hpc/group/viplab/zzz3/SNP_Segmentation/Files/Python/AAR-Net/';\n",
    "torch_path = r'/hpc/group/viplab/zzz3/SNP_Segmentation/Files/Torch/AAR-Net/';\n",
    "\n",
    "#Load Numpy Files\n",
    "SNP_Train = np.load(python_path + 'AAR_Net_Images_Training_SNP.npy');\n",
    "SNP_Val = np.load(python_path + 'AAR_Net_Images_Validation_SNP.npy');\n",
    "SNP = np.concatenate((SNP_Train, SNP_Val), 0);\n",
    "Epithelium_Train = np.load(python_path + 'AAR_Net_Images_Training_Epithelium.npy');\n",
    "Epithelium_Val = np.load(python_path + 'AAR_Net_Images_Validation_Epithelium.npy');\n",
    "Epithelium = np.concatenate((Epithelium_Train, Epithelium_Val), 0);\n",
    "Stroma_Train = np.load(python_path + 'AAR_Net_Images_Training_Stroma.npy');\n",
    "Stroma_Val = np.load(python_path + 'AAR_Net_Images_Validation_Stroma.npy');\n",
    "Stroma = np.concatenate((Stroma_Train, Stroma_Val), 0);\n",
    "\n",
    "#Print Size\n",
    "print(np.shape(SNP))\n",
    "print(np.shape(Epithelium))\n",
    "print(np.shape(Stroma))\n",
    "\n",
    "\n",
    "#Concatenate\n",
    "ccm_images = np.concatenate((SNP, Epithelium, Stroma), 0);\n",
    "ccm_labels = np.concatenate((np.zeros((np.shape(SNP)[0],1)), np.ones((np.shape(Epithelium)[0],1)), 2*np.ones((np.shape(Stroma)[0],1))), 0);\n",
    "\n",
    "\n",
    "#Shuffle\n",
    "indices = np.arange(0,np.shape(ccm_images)[0]);\n",
    "np.random.shuffle(indices);\n",
    "ccm_images = ccm_images[indices]\n",
    "ccm_labels = ccm_labels[indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6sO_DZYIKKHq"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Hyper Parameters\n",
    "n_epochs = 400;\n",
    "batch_size = 5;\n",
    "lr = 0.002;\n",
    "b1 = 0.5;\n",
    "b2 = 0.999;\n",
    "latent_dim = 400;\n",
    "n_classes = 3;\n",
    "img_size = 192;\n",
    "channels = 1;\n",
    "experiment = 'Original'\n",
    "\n",
    "\n",
    "# Loss functions\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "auxiliary_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "\n",
    "#Cast to Cuda\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    adversarial_loss.cuda()\n",
    "    auxiliary_loss.cuda()\n",
    "    FloatTensor = torch.cuda.FloatTensor\n",
    "    LongTensor = torch.cuda.LongTensor\n",
    "else:\n",
    "    FloatTensor = torch.FloatTensor\n",
    "    LongTensor = torch.LongTensor\n",
    "\n",
    "#Attempt to use GPU instead of CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu');\n",
    "\n",
    "\n",
    "# Initialize weights\n",
    "generator.apply(weights_init_normal)\n",
    "discriminator.apply(weights_init_normal)\n",
    "\n",
    "\n",
    "# Configure data loader\n",
    "dataset = BasicDataset(ccm_images, ccm_labels);\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True);\n",
    "       \n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "# Schedulers\n",
    "scheduler_G = StepLR(optimizer_G, step_size = 100, gamma = 0.5)\n",
    "scheduler_D = StepLR(optimizer_D, step_size = 100, gamma = 0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpFtvcxPjguo"
   },
   "source": [
    "# **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W22mQC0hgDr9",
    "outputId": "b8d87590-3150-4776-ea2d-4032505213bb"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "\n",
    "discriminator_loss_net =np.zeros((n_epochs,1));\n",
    "generator_loss_net = np.zeros((n_epochs,1));\n",
    "discriminator_accuracy_net =np.zeros((n_epochs,1));\n",
    "SSIM_results_net = np.zeros((n_epochs,3));\n",
    "\n",
    "\n",
    "#Iterate through Training Epochs\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "\n",
    "\n",
    "    discriminator_loss = [];\n",
    "    generator_loss = [];\n",
    "    discriminator_accuracy =[];\n",
    "\n",
    "    #Iterate though Images in Dataloader\n",
    "    idx = 0;\n",
    "    for batch in dataloader:\n",
    "\n",
    "\n",
    "        #Load Batch\n",
    "        real_imgs = torch.from_numpy(np.reshape(np.array(batch['ccm_images']), (-1,1,192,192))).to(device=device, dtype=torch.float32);\n",
    "        labels_real = torch.from_numpy(np.reshape(np.array(batch['ccm_labels']), (-1,1,1,1))).to(device=device, dtype=torch.long).squeeze();\n",
    "\n",
    "\n",
    "        #Obtain Batch Size\n",
    "        batch_size = real_imgs.shape[0]\n",
    "\n",
    "        # Adversarial Ground Truth Labels\n",
    "        real = Variable(FloatTensor(batch_size, 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(FloatTensor(batch_size, 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        #Zero Grad: Generator\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Sample noise and labels as generator input\n",
    "        z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, latent_dim))))\n",
    "        labels_fake = Variable(LongTensor(np.random.randint(0, n_classes, batch_size)))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        fake_imgs = generator(z, labels_fake)\n",
    "\n",
    "\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        validity_fake, pred_labels_fake = discriminator(fake_imgs)\n",
    "        g_loss = (adversarial_loss(validity_fake, real) + auxiliary_loss(pred_labels_fake, labels_fake))/2.0;\n",
    "\n",
    "\n",
    "        #Back Propagation: Generator\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "      \n",
    "        \n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "\n",
    "        #Zero Grad: Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "\n",
    "        # Loss for real images\n",
    "        validity_real, pred_labels_real = discriminator(real_imgs)\n",
    "        d_real_loss = (adversarial_loss(validity_real, real) + auxiliary_loss(pred_labels_real, labels_real)) / 2.0      \n",
    "\n",
    "\n",
    "        # Loss for fake images\n",
    "        validity_fake, pred_labels_fake = discriminator(fake_imgs.detach())\n",
    "        d_fake_loss = (adversarial_loss(validity_fake, fake) + auxiliary_loss(pred_labels_fake, labels_fake)) / 2.0\n",
    "\n",
    "\n",
    "        # Total discriminator loss\n",
    "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "\n",
    "        \n",
    "        #Back Propagation: Discriminator\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "\n",
    "\n",
    "        # Calculate discriminator accuracy\n",
    "        pred = np.concatenate([validity_real.data.cpu().numpy(), validity_fake.data.cpu().numpy()], axis=0)\n",
    "        gt = np.concatenate([real.data.cpu().numpy(), fake.data.cpu().numpy()], axis=0)\n",
    "        d_acc = np.mean(np.argmax(pred, axis=1) == gt)\n",
    "\n",
    "        \n",
    "        #Log Loss and Accuracy\n",
    "        discriminator_loss.append(d_loss.item());\n",
    "        generator_loss.append(g_loss.item());\n",
    "        discriminator_accuracy.append(100 * d_acc);\n",
    "\n",
    "        \n",
    "        #Save Results\n",
    "        if idx ==0:\n",
    "\n",
    "            sample_image(n_row=3, epochs=epoch)\n",
    "\n",
    "        #Increment\n",
    "        idx = idx + 1;\n",
    "\n",
    "\n",
    "\n",
    "    #Print Progress\n",
    "    print(\n",
    "        \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %d%%] [G loss: %f]\"\n",
    "        % (epoch, n_epochs, idx, len(dataloader), np.nanmean(np.array(discriminator_loss)), np.nanmean(np.array(discriminator_accuracy)), np.nanmean(np.array(generator_loss)))\n",
    "    )\n",
    "\n",
    "    #Log Loss and Accuracy\n",
    "    discriminator_loss_net[epoch,0] = np.nanmean(np.array(discriminator_loss));\n",
    "    generator_loss_net[epoch,0] = np.nanmean(np.array(generator_loss));\n",
    "    discriminator_accuracy_net[epoch,0] = np.nanmean(np.array(discriminator_accuracy));\n",
    "\n",
    "    #Structural Similarity Index Metric\n",
    "    SSIM_results = np.zeros((500,3));\n",
    "    for i in range(0,500):\n",
    "\n",
    "        for j in range(0,3):\n",
    "            # Generate a batch of images\n",
    "            z = Variable(FloatTensor(np.random.normal(0, 1, (2, latent_dim))))\n",
    "            labels_fake = Variable(LongTensor(np.array([j, j])));               \n",
    "            fake_imgs = generator(z, labels_fake)\n",
    "            img_1 = fake_imgs[0].squeeze().cpu().detach().numpy();\n",
    "            img_2 = fake_imgs[1].squeeze().cpu().detach().numpy();\n",
    "            SSIM_results[i,j] = ssim(img_1,img_2);\n",
    "\n",
    "    SSIM_results_net[epoch,0] = np.nanmean(SSIM_results[:,0]);\n",
    "    SSIM_results_net[epoch,1] = np.nanmean(SSIM_results[:,1]);\n",
    "    SSIM_results_net[epoch,2] = np.nanmean(SSIM_results[:,2]);\n",
    "\n",
    "    #Save Data\n",
    "    np.save(torch_path + 'Discriminator_Loss_' + experiment +'.npy', discriminator_loss_net);\n",
    "    np.save(torch_path + 'Generator_Loss_' + experiment +'.npy', generator_loss_net);\n",
    "    np.save(torch_path +  'Discriminator_Accuracy_' + experiment +'.npy', discriminator_accuracy_net);\n",
    "    np.save(torch_path +  'SSIM_Results_' + experiment +'.npy', SSIM_results_net);\n",
    "\n",
    "\n",
    "    #Scheduler Step\n",
    "    scheduler_G.step() \n",
    "    scheduler_D.step()   \n",
    "\n",
    "\n",
    "    #Save Generator and Discriminator\n",
    "    torch.save(generator.state_dict(), torch_path +  'Generator_' + experiment + '.pth');\n",
    "    torch.save(discriminator.state_dict(), torch_path  +  'Discriminator_' + experiment + '.pth');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
