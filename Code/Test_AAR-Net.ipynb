{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6909e93-12d6-4308-b54c-acf5907742d6",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589aff98-f2cc-4f33-9f7b-16ea0fd64dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Python Packages\n",
    "import copy\n",
    "from functools import reduce\n",
    "from glob import glob\n",
    "from glob import iglob\n",
    "import logging\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from operator import __add__\n",
    "import os\n",
    "from os.path import splitext\n",
    "from os import listdir\n",
    "import pandas as pd;\n",
    "import PIL\n",
    "from PIL import Image, ImageEnhance\n",
    "from PIL import Image, ImageOps\n",
    "from random import sample\n",
    "from random import randint\n",
    "import random;\n",
    "from scipy import stats\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from scipy.ndimage.measurements import label\n",
    "from scipy.special import softmax\n",
    "from skimage import exposure\n",
    "from skimage import feature\n",
    "from skimage import transform as tf\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "from torch.nn.modules import Conv2d, Module\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from typing import Any\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad07153-e45e-4ae3-9eb7-821b0ec33637",
   "metadata": {},
   "source": [
    "Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c7dd3e-62b3-456d-96e8-bd567e38af04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaborConv2d(Module):\n",
    "#    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1,groups=1,bias=False, padding_mode=\"zeros\"):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=48, dilation=1,groups=1,bias=False, padding_mode=\"reflect\"): \n",
    "        super().__init__()\n",
    "        self.is_calculated = False\n",
    "\n",
    "        self.conv_layer = Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode)\n",
    "        self.kernel_size = self.conv_layer.kernel_size\n",
    "\n",
    "        # small addition to avoid division by zero\n",
    "        self.delta = 1e-3\n",
    "\n",
    "        #Frequency\n",
    "        self.freq = Parameter(\n",
    "            (math.pi / 2)\n",
    "            * math.sqrt(2)\n",
    "            ** (-torch.randint(0, 5, (out_channels, in_channels))).type(torch.Tensor),\n",
    "            requires_grad=True,\n",
    "        )\n",
    "        #Theta\n",
    "        self.theta = Parameter(\n",
    "            (math.pi / 8)\n",
    "            * torch.randint(0, 8, (out_channels, in_channels)).type(torch.Tensor),\n",
    "            requires_grad=True,\n",
    "        )\n",
    "        #Sigma\n",
    "        self.sigma = Parameter(math.pi / self.freq, requires_grad=True)\n",
    "\n",
    "        #Psi\n",
    "        self.psi = Parameter(\n",
    "            math.pi * torch.rand(out_channels, in_channels), requires_grad=True\n",
    "        )\n",
    "\n",
    "        self.x0 = Parameter(\n",
    "            torch.ceil(torch.Tensor([self.kernel_size[0] / 2]))[0], requires_grad=False\n",
    "        )\n",
    "        self.y0 = Parameter(\n",
    "            torch.ceil(torch.Tensor([self.kernel_size[1] / 2]))[0], requires_grad=False\n",
    "        )\n",
    "\n",
    "        self.y, self.x = torch.meshgrid(\n",
    "            [\n",
    "                torch.linspace(-self.x0 + 1, self.x0 + 0, self.kernel_size[0]),\n",
    "                torch.linspace(-self.y0 + 1, self.y0 + 0, self.kernel_size[1]),\n",
    "            ]\n",
    "        )\n",
    "        self.y = Parameter(self.y.clone());\n",
    "        self.x = Parameter(self.x.clone());\n",
    "\n",
    "        self.weight = Parameter(\n",
    "            torch.empty(self.conv_layer.weight.shape, requires_grad=True),\n",
    "            requires_grad=True,\n",
    "        )\n",
    "\n",
    "        self.register_parameter(\"freq\", self.freq)\n",
    "        self.register_parameter(\"theta\", self.theta)\n",
    "        self.register_parameter(\"sigma\", self.sigma)\n",
    "        self.register_parameter(\"psi\", self.psi)\n",
    "        self.register_parameter(\"x_shape\", self.x0)\n",
    "        self.register_parameter(\"y_shape\", self.y0)\n",
    "        self.register_parameter(\"y_grid\", self.y)\n",
    "        self.register_parameter(\"x_grid\", self.x)\n",
    "        self.register_parameter(\"weight\", self.weight)\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        if self.training:\n",
    "            self.calculate_weights()\n",
    "            self.is_calculated = False\n",
    "        if not self.training:\n",
    "            if not self.is_calculated:\n",
    "                self.calculate_weights()\n",
    "                self.is_calculated = True\n",
    "        return self.conv_layer(input_tensor)\n",
    "\n",
    "    def calculate_weights(self):\n",
    "        for i in range(self.conv_layer.out_channels):\n",
    "            for j in range(self.conv_layer.in_channels):\n",
    "                sigma = self.sigma[i, j].expand_as(self.y) \n",
    "                freq = self.freq[i, j].expand_as(self.y) \n",
    "                theta = self.theta[i, j].expand_as(self.y) \n",
    "                psi = self.psi[i, j].expand_as(self.y) \n",
    "\n",
    "                rotx = self.x * torch.cos(theta) + self.y * torch.sin(theta)\n",
    "                roty = -self.x * torch.sin(theta) + self.y * torch.cos(theta)\n",
    "\n",
    "                g = torch.exp(\n",
    "                    -0.5 * ((rotx ** 2 + roty ** 2) / (sigma + self.delta) ** 2)\n",
    "                )\n",
    "                g = g * torch.cos(freq * rotx + psi)\n",
    "                g = g / (2 * math.pi * sigma ** 2)\n",
    "                self.conv_layer.weight.data[i, j] = g\n",
    "\n",
    "    def _forward_unimplemented(self, *inputs: Any):\n",
    "        \"\"\"\n",
    "        code checkers makes implement this method,\n",
    "        looks like error in PyTorch\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = torch.tensor([x2.size()[2] - x1.size()[2]])\n",
    "        diffX = torch.tensor([x2.size()[3] - x1.size()[3]])\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class filt_cat(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x1, x2):     \n",
    "\n",
    "        # input is CHW\n",
    "        diffY = torch.tensor([x2.size()[2] - x1.size()[2]])\n",
    "        diffX = torch.tensor([x2.size()[3] - x1.size()[3]])\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return x;\n",
    "\n",
    "\n",
    "\n",
    "class AAR_Net(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(AAR_Net, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "\n",
    "        self.g0 = GaborConv2d(n_channels, n_channels, kernel_size=(144, 144))\n",
    "\n",
    "        \n",
    "        self.fc = filt_cat(n_channels, 2*n_channels)\n",
    "        self.inc = DoubleConv(2*n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 512)\n",
    "        self.up1 = Up(1024, 256, bilinear)\n",
    "        self.up2 = Up(512, 128, bilinear)\n",
    "        self.up3 = Up(256, 64, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        f = self.g0(x)\n",
    "        x0 = self.fc(f,x);\n",
    "        x1 = self.inc(x0)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        x = self.outc(x)\n",
    "        m = nn.Softmax(dim=1)\n",
    "        logits = m(x)\n",
    "        \n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7513d60-0f26-4436-ab27-989bc97e5fe8",
   "metadata": {},
   "source": [
    "Gaussian Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebc57f9-8d0a-4fbf-a26e-dcd21b921c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fspecial_gauss(size, sigma):\n",
    "\n",
    "    \"\"\"Function to mimic the 'fspecial' gaussian MATLAB function\n",
    "    \"\"\"\n",
    "\n",
    "    x, y = np.mgrid[-size//2 + 1:size//2 + 1, -size//2 + 1:size//2 + 1]\n",
    "    g = np.exp(-((x**2 + y**2)/(2.0*sigma**2)))\n",
    "    return g\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5aaa78-bcee-4df4-8675-9e7b2a6a7019",
   "metadata": {},
   "source": [
    "Test Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdea1c52-396f-4c0c-8119-1341f63b84a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_net(python_path, torch_path, img_path, Experiment_Name, Model_Name, tissues, channels, Plot_Figures, Save_Figures):\n",
    "    \n",
    " \n",
    "\n",
    "    #Cast to Cuda\n",
    "    cuda = True if torch.cuda.is_available() else False\n",
    "    if cuda:\n",
    "        FloatTensor = torch.cuda.FloatTensor\n",
    "        LongTensor = torch.cuda.LongTensor\n",
    "    else:\n",
    "        FloatTensor = torch.FloatTensor\n",
    "        LongTensor = torch.LongTensor\n",
    "\n",
    "    #Attempt to use GPU instead of CPU\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu');\n",
    "\n",
    "\n",
    "    #Load Numpy Files\n",
    "    SNP = np.load(python_path + 'SNP_Net_Images.npy');\n",
    "\n",
    "    #Weight\n",
    "    weight_kernel = fspecial_gauss(192, 20);\n",
    "    \n",
    "    #Load Models\n",
    "    for g in range(0,5):\n",
    "\n",
    "        validation = np.load(torch_path  +'Validation_Dice_'+  Model_Name +'_' + Experiment_Name + '_Group_' + str(g)  +'.npy').squeeze();       \n",
    "        epoch = np.argmax(validation[0,40:]) + 40;\n",
    "\n",
    "\n",
    "        #Model\n",
    "        if(g==0):\n",
    "            net_0 = AAR_Net(n_channels=channels, n_classes=tissues);\n",
    "            net_0.load_state_dict(torch.load(torch_path + Model_Name + '_' + Experiment_Name + '_Group_' + str(g) + '_Epoch_' +str(epoch+1) +'.pth', map_location=device));\n",
    "            net_0.to(device=device);  \n",
    "            net_0.eval();\n",
    "        elif(g==1):\n",
    "            net_1 =AAR_Net(n_channels=channels, n_classes=tissues);\n",
    "            net_1.load_state_dict(torch.load(torch_path + Model_Name + '_' + Experiment_Name + '_Group_' + str(g) + '_Epoch_' +str(epoch+1) +'.pth', map_location=device));\n",
    "            net_1.to(device=device);  \n",
    "            net_1.eval()        \n",
    "        elif(g==2):\n",
    "            net_2 =AAR_Net(n_channels=channels, n_classes=tissues);\n",
    "            net_2.load_state_dict(torch.load(torch_path + Model_Name + '_' + Experiment_Name + '_Group_' + str(g) + '_Epoch_' +str(epoch+1) +'.pth', map_location=device));\n",
    "            net_2.to(device=device);  \n",
    "            net_2.eval()           \n",
    "        elif(g==3):\n",
    "            net_3 = AAR_Net(n_channels=channels, n_classes=tissues);\n",
    "            net_3.load_state_dict(torch.load(torch_path + Model_Name + '_' + Experiment_Name + '_Group_' + str(g) + '_Epoch_' +str(epoch+1) +'.pth', map_location=device));\n",
    "            net_3.to(device=device);  \n",
    "            net_3.eval()  \n",
    "        elif(g==4):\n",
    "            net_4 = AAR_Net(n_channels=channels, n_classes=tissues); \n",
    "            net_4.load_state_dict(torch.load(torch_path + Model_Name + '_' + Experiment_Name + '_Group_' + str(g) + '_Epoch_' +str(epoch+1) +'.pth', map_location=device));\n",
    "            net_4.to(device=device);  \n",
    "            net_4.eval()  \n",
    " \n",
    "\n",
    "\n",
    "    #Iterate through Images\n",
    "    AAR_Masks = [];\n",
    "    for idx in range(0, np.shape(SNP)[0]):\n",
    "\n",
    "\n",
    "        #Select Image\n",
    "        img = SNP[idx, :,:].copy();\n",
    "\n",
    "        #Initialize\n",
    "        collective = np.zeros((tissues,384,384));\n",
    "        weight = np.zeros((tissues,384,384));\n",
    "         \n",
    "            \n",
    "        #Iterate\n",
    "        for row in range(0,200,8):\n",
    "            for col in range(0,200,8):\n",
    "\n",
    "                #Select Window\n",
    "                cropped_img = img[row:row+192,col:col+192].copy();\n",
    "\n",
    "\n",
    "\n",
    "                #Normalize Window\n",
    "                cropped_img = (cropped_img - np.min(cropped_img))/(np.max(cropped_img) - np.min(cropped_img))\n",
    "                cropped_img = cropped_img - 0.5;\n",
    "\n",
    "                #Flip\n",
    "                cropped_img_0 = cropped_img.copy();\n",
    "                cropped_img_1 = np.fliplr(cropped_img).copy();\n",
    "                cropped_img_2 = np.flipud(cropped_img).copy();\n",
    "                cropped_img_3 = np.fliplr(np.flipud(cropped_img).copy()).copy();\n",
    "\n",
    "                #Expand Dim\n",
    "                cropped_img_0 = np.expand_dims(cropped_img_0,axis = 0);\n",
    "                cropped_img_1 = np.expand_dims(cropped_img_1,axis = 0);\n",
    "                cropped_img_2 = np.expand_dims(cropped_img_2,axis = 0);\n",
    "                cropped_img_3 = np.expand_dims(cropped_img_3,axis = 0);\n",
    "\n",
    "                #Concatenate\n",
    "                cropped_img = np.concatenate((cropped_img_0, cropped_img_1, cropped_img_2, cropped_img_3), 0);\n",
    "                cropped_img = np.reshape(cropped_img, (-1,1,192,192))\n",
    "\n",
    "\n",
    "                #Pre-process the Input Image \n",
    "                input_img = torch.from_numpy(cropped_img).to(device=device, dtype=torch.float32);\n",
    "\n",
    "\n",
    "                with torch.no_grad():\n",
    "\n",
    "                    #Predict the Mask                         \n",
    "                    output = net_0(input_img) + net_1(input_img) + net_2(input_img) + net_3(input_img) + net_4(input_img);\n",
    "\n",
    "\n",
    "                    #Extract Outputs  \n",
    "                    output = output.cpu().detach().numpy();\n",
    "                    output_0 = output[0].squeeze();\n",
    "                    output_1 = output[1].squeeze();\n",
    "                    output_2 = output[2].squeeze();\n",
    "                    output_3 = output[3].squeeze();                    \n",
    "\n",
    "\n",
    "                    #Flip\n",
    "                    output_1[0] = np.fliplr(output_1[0]).copy();\n",
    "                    output_1[1] = np.fliplr(output_1[1]).copy();\n",
    "                    output_1[2] = np.fliplr(output_1[2]).copy();\n",
    "                    output_2[0] = np.flipud(output_2[0]).copy();\n",
    "                    output_2[1] = np.flipud(output_2[1]).copy();\n",
    "                    output_2[2] = np.flipud(output_2[2]).copy();\n",
    "                    output_3[0] = np.fliplr(np.flipud(output_3[0]).copy()).copy();\n",
    "                    output_3[1] = np.fliplr(np.flipud(output_3[1]).copy()).copy();\n",
    "                    output_3[2] = np.fliplr(np.flipud(output_3[2]).copy()).copy();\n",
    "\n",
    "\n",
    "                    #Multiply by Weight\n",
    "                    mult_output_0 = np.multiply(softmax(output_0,axis = 0),weight_kernel);\n",
    "                    mult_output_1 = np.multiply(softmax(output_1,axis = 0),weight_kernel);\n",
    "                    mult_output_2 = np.multiply(softmax(output_2,axis = 0),weight_kernel);\n",
    "                    mult_output_3 = np.multiply(softmax(output_3,axis = 0),weight_kernel);\n",
    "\n",
    "                    #Add to Collective\n",
    "                    collective[:,row:row+192,col:col+192] += mult_output_0 + mult_output_1 + mult_output_2 + mult_output_3;\n",
    "                    weight[:,row:row+192,col:col+192] +=4*weight_kernel ;\n",
    "\n",
    "        #Divide by Count\n",
    "        collective = np.divide(collective, weight);\n",
    "        max_mask = np.argmax(collective, axis = 0);\n",
    "        \n",
    "        #Save Masks\n",
    "        AAR_Masks.append(max_mask);\n",
    "        np.save(python_path  + 'AAR_Net_Masks.npy', np.array(AAR_Masks));\n",
    "        \n",
    "        \n",
    "        if(Plot_Figures):\n",
    "            \n",
    "            #Plot Original Image\n",
    "            plt.figure;\n",
    "            plt.imshow(img,cmap='gray')\n",
    "            plt.show()        \n",
    "\n",
    "        \n",
    "        if(Plot_Figures or Save_Figures):\n",
    "        \n",
    "            #Convert Mask to Color\n",
    "            color_new_mask_1 = np.zeros((384,384));\n",
    "            color_new_mask_2 = np.zeros((384,384));\n",
    "            color_new_mask_3 = np.zeros((384,384));\n",
    "            color_new_mask_1[np.where(max_mask==0)] = 255;\n",
    "            color_new_mask_2[np.where(max_mask==2)] = 255;\n",
    "            color_new_mask_3[np.where(max_mask==1)] = 255;\n",
    "            color_new_mask = np.zeros((384,384,3));\n",
    "            color_new_mask[:,:,0] = color_new_mask_1;\n",
    "            color_new_mask[:,:,1] = color_new_mask_3\n",
    "            color_new_mask[:,:,2] = color_new_mask_2;\n",
    "            color_new_mask = np.array(color_new_mask, dtype = 'uint8')\n",
    "\n",
    "        if(Plot_Figures):\n",
    "            \n",
    "            #Plot Mask\n",
    "            plt.figure;\n",
    "            plt.imshow(color_new_mask)\n",
    "            plt.show()\n",
    "        \n",
    "        \n",
    "        if(Save_Figures):\n",
    "            fname = 'AAR_' + str(idx) + '.jpg';\n",
    "            save_img = Image.fromarray(color_new_mask);\n",
    "            save_img.save(img_path + fname)               \n",
    "    \n",
    "    \n",
    "    AAR_Masks = np.array(AAR_Masks)\n",
    "    return AAR_Masks;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08442de-edc8-4820-9d1e-b767def77a93",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e54177-7cca-4294-b3d9-234f9132f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "Experiment_Name = 'Original';\n",
    "Model_Name = 'AAR_Net';\n",
    "tissues = 3;\n",
    "channels = 1;\n",
    "Plot_Figures = True;\n",
    "Save_Figures = True;\n",
    "\n",
    "#Path\n",
    "python_path = r'/hpc/group/viplab/zzz3/SNP_Segmentation/Files/Python/SNP-Net/';\n",
    "torch_path = r'/hpc/group/viplab/zzz3/SNP_Segmentation/Files/Torch/AAR-Net/';\n",
    "img_path = r'/hpc/group/viplab/zzz3/SNP_Segmentation/Files/Images/AAR-Net/';\n",
    "\n",
    "#Test AAR-Net\n",
    "AAR_Masks = test_net(python_path, torch_path, img_path, Experiment_Name, Model_Name, tissues, channels, Plot_Figures, Save_Figures);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc36828c-9df8-40b9-8d59-78a3e3a65526",
   "metadata": {},
   "source": [
    "Number of Applanation Artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255503b0-0461-4e19-b571-991319aa7806",
   "metadata": {},
   "outputs": [],
   "source": [
    "               \n",
    "#Correct Applanation Artifact Removal\n",
    "masks_AAR = np.load(python_path  + 'AAR_Net_Masks.npy');  \n",
    "masks_AAR = (masks_AAR==0);\n",
    "masks_AAR = masks_AAR *1.0;\n",
    "\n",
    "\n",
    "\n",
    "#Count\n",
    "count = 0;\n",
    "for i in range(0, np.shape(masks_AAR)[0]):\n",
    "\n",
    "    mask_AAR = masks_AAR[i];\n",
    "    if(np.sum(mask_AAR) > 0.95*np.size(mask_AAR)):\n",
    "        continue;\n",
    "\n",
    "    else:\n",
    "        count = count + 1;\n",
    "\n",
    "print('Number of SNP Images with Applanation Artifacts: ' + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64fb95e-c0e8-4905-a4bc-94945580048d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
